{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio_4_Parte_1_FranciscoMena.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHopPtVaNF1K"
      },
      "source": [
        "# **Diplomado IA: Aplicaciones de Inteligencia Artificial I - Parte 2**. <br> Práctico 4: Generación de resúmenes\n",
        "---\n",
        "---\n",
        "\n",
        "**Profesores:**\n",
        "- Vladimir Araujo\n",
        "- Felipe del Río\n",
        "\n",
        "**Ayudante:**\n",
        "- Nissim Ergas\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIdAKAdELPSl"
      },
      "source": [
        "# **Instrucciones Generales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmhnKlt8Ns7A"
      },
      "source": [
        "El siguiente práctico se debe realizar de forma **individual**. El formato de entregar es el **archivo .ipynb con todas las celdas ejecutadas**. Todas las preguntas deben ser respondida en celdas de texto. No se aceptará el _output_ de una celda de código como respuesta.\n",
        "\n",
        "**Nombre:** FRANCISCO MENA\n",
        "\n",
        "**Fecha de entrega: Viernes 8 de enero.**\n",
        "\n",
        "El siguiente práctico cuanta con 2 secciones donde cada una contendrá 1 o más actividades a realizar. Algunas actividades correspondrán a escribir código y otras a responder preguntas. \n",
        "\n",
        "**Importante.** Para facilitar su ejecución, cada sección puede ser ejecutada independientemente.\n",
        "\n",
        "Se recomienda **fuertemente** revisar las secciones donde se entrega código porque algunas actividades de código pueden reutilizar el mismo código pero con cambios en algunas líneas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEloa5uXLIPK"
      },
      "source": [
        "# **Agenda**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGlX5q_pQYRa",
        "colab_type": "toc"
      },
      "source": [
        ">[Diplomado IA: Aplicaciones de Inteligencia Artificial I - Parte 2.  Práctico 4: Generación de resúmenes](#scrollTo=tHopPtVaNF1K)\n",
        "\n",
        ">[Instrucciones Generales](#scrollTo=uIdAKAdELPSl)\n",
        "\n",
        ">[Agenda](#scrollTo=kEloa5uXLIPK)\n",
        "\n",
        ">[Parte I: Generación de Resumenes Extractivos](#scrollTo=Ww8OOQyAnBQj)\n",
        "\n",
        ">>[Preámbulo](#scrollTo=jdQWS0upPEir)\n",
        "\n",
        ">>>[Funciones Auxiliares](#scrollTo=UBo9B9xujjlr)\n",
        "\n",
        ">>[Modelo de resumenes extractivo](#scrollTo=7b6hqPsgPKhM)\n",
        "\n",
        ">>>[Entrenamiento](#scrollTo=Ge3EMmSDSut6)\n",
        "\n",
        ">>>[Configuración de nuestra ejecución](#scrollTo=3Cw_GQPmgsul)\n",
        "\n",
        ">>>[Datos](#scrollTo=dV73kM9nihPx)\n",
        "\n",
        ">>>[Evaluación](#scrollTo=l5hju-cES9hD)\n",
        "\n",
        ">>>[Actividad 1](#scrollTo=cZ3WoiKWYMAz)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww8OOQyAnBQj"
      },
      "source": [
        "# Parte I: Generación de Resumenes Extractivos\n",
        "\n",
        "En esta actividad aplicaremos lo que vimos acerca de métodos para resumir de forma extractiva. Nos basaremos en un modelo que sigue el proceso planteado para modelos extractivos que vimos en clase. Este modelo viene del trabajo [Fine-tune BERT for Extractive Summarization](https://arxiv.org/pdf/1903.10318.pdf), a continuación se detalla un diagrama mostrando la forma en que funciona este modelo. \n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://docs.google.com/drawings/d/e/2PACX-1vSa16s1rK-JLF_E13C5E4vLe6qRp7azTi-7tLXpUTVisr-OUntDVs-nezE4sWH4QCOLPdwf_JCxvIut/pub?w=765&h=494' height=\"250\" />\n",
        "<figcaption>Cálculo de precision y recall.</figcaption>\n",
        "</center>\n",
        "\n",
        "</figure>\n",
        "\n",
        "Por el momento no entraremos en detalle de la arquitectura de *transformer*, pues lo verán en el futuro. Pero si les gana la curiosidad, les recomiendo leer el paper que los propuso, [\"Attention is all you need\"](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) en NeurIPS 2017, y lo mismo con el paper de [BERT](https://arxiv.org/pdf/1810.04805.pdf) publicado en ACL 2019.\n",
        "\n",
        "Este modelo de lenguaje será visto en la próxima sección del diplomado. \n",
        "\n",
        "\n",
        "<small>Basado en la [implementación oficial](https://github.com/nlpyang/BertSum) de este trabajo.</small>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdQWS0upPEir"
      },
      "source": [
        "## Preámbulo\n",
        "Primero debemos copiar el dataset y otros archivos que utilizaremos hacia colab. El dataset lo decomprimiremos dentro del directorio data, que recién creamos. También instalaremos algunas de las librerías que ocuparemos durante esta actividad. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h477H3yGmxr5"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V07Zjg-AN7YM"
      },
      "source": [
        "Primero que todo descargaremos las librerías que vamos a utilizar, en este caso debemos modificar la versión de PyTorch que utilizaremos a la `1.1.0`. Esto se debe a que la implementación original utilizó esa versión y así mantenmos mejor compatibilidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAWO7bxzmg8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb6e084-b77a-468e-cb42-cbd4b354c8a5"
      },
      "source": [
        "!wget -nc https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl -q --show-progress\n",
        "!wget -nc https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl -q --show-progress\n",
        "!pip uninstall -qy torch torchvision fastai\n",
        "!pip install -q urllib3==1.25.10 folium==0.2.1 # Nos evitan mensajes de errores, aunq ue no influyen en la ejecución\n",
        "!pip install -q torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install -q torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch-1.1.0-cp36-cp 100%[===================>] 734.97M  76.6MB/s    in 11s     \n",
            "torchvision-0.3.0-c 100%[===================>]   2.46M  15.1MB/s    in 0.2s    \n",
            "\u001b[K     |████████████████████████████████| 133kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25h  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEJ0Oh97tmcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdce3f44-7dee-4d14-ba69-6f92c1fcad4e"
      },
      "source": [
        "!pip install -q pytorch_pretrained_bert tensorboardX pyrouge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 133kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 13.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.2MB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25h  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDGkYrTFEtEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dba50a2-8fba-4750-9212-b161cb9c246c"
      },
      "source": [
        "!git clone --progress https://github.com/nlpyang/BertSum.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BertSum'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Total 301 (delta 0), reused 0 (delta 0), pack-reused 301\u001b[K\n",
            "Receiving objects: 100% (301/301), 15.03 MiB | 20.42 MiB/s, done.\n",
            "Resolving deltas: 100% (174/174), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mkIs3JqNZXq"
      },
      "source": [
        "Debemos también descargar los archivos del modelo pre-entrenado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ieFHF1RmgzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1b51d1-6083-45bc-bf02-d960fb6897bf"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/Hernan4444/MyScripts/master/google_drive/google_api.py -q --show-progress\n",
        "\n",
        "import os\n",
        "from google_api import download_file_without_authenticate\n",
        "\n",
        "if not os.path.exists('lab4.zip'): \n",
        "    download_file_without_authenticate('18ecT1r9jFGyChATPwTdRgvj9dKctd3sS', 'lab4.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rgoogle_api.py         0%[                    ]       0  --.-KB/s               \rgoogle_api.py       100%[===================>]   5.55K  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbpVVeHzOgSi"
      },
      "source": [
        "También debemos descargar los datos en donde probaremos nuestros modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvdAiV52oCMo"
      },
      "source": [
        "!unzip -nq lab4.zip -d .\n",
        "!mv lab4/activity\\ 1/model.pt BertSum/models/model.pt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqvhKJjpyMU4"
      },
      "source": [
        "download_file_without_authenticate('1x0d61LP9UAN389YN00z0Pv-7jQgirVg6', 'bertsum_data.zip')\n",
        "!unzip -nq bertsum_data.zip -d BertSum/bert_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWok_BDRsEZj"
      },
      "source": [
        "os.chdir('/content/BertSum/src/')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6NkQ_AOOtcT"
      },
      "source": [
        "Finalmente configuraremos nuestra ejecución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdZq08loji77"
      },
      "source": [
        "class Args():\n",
        "    encoder='classifier'                        # Tipo de encoder a utilizar\n",
        "    mode='test'                                 # Testearemos el modelo, no lo entrenaremos\n",
        "    bert_data_path='../bert_data/cnndm'         # Path a los datos\n",
        "    model_path='../models/'                     # Path a los checkpoints\n",
        "    result_path='../results/cnndm'              \n",
        "    temp_dir='../temp'\n",
        "    bert_config_path='../bert_config_uncased_base.json' # Archivo de configuración de hugginface de BERT \n",
        "    batch_size=1000\n",
        "    use_interval=True\n",
        "    hidden_size=128\n",
        "    ff_size=512\n",
        "    heads=4\n",
        "    inter_layers=2\n",
        "    rnn_size=512\n",
        "    param_init=0\n",
        "    param_init_glorot=True\n",
        "    dropout=0.1\n",
        "    optim='adam'                                # Optimizador a utilizar\n",
        "    lr=1                                        # Tasa de aprendizaje\n",
        "    beta1= 0.9\n",
        "    beta2=0.999\n",
        "    decay_method=''\n",
        "    warmup_steps=8000\n",
        "    max_grad_norm=0\n",
        "    save_checkpoint_steps=5\n",
        "    accum_count=1\n",
        "    world_size=1\n",
        "    report_every=1\n",
        "    train_steps=1000\n",
        "    recall_eval=False\n",
        "    visible_gpus=-1\n",
        "    gpu_ranks=[0]\n",
        "    log_file='../logs/cnndm.log'\n",
        "    dataset=''\n",
        "    seed=1666\n",
        "    test_all=False\n",
        "    test_from=''\n",
        "    train_from=''\n",
        "    report_rouge=False\n",
        "    block_trigram=True   "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBo9B9xujjlr"
      },
      "source": [
        "### Funciones Auxiliares\n",
        "\n",
        "Definamos algunas funciones que nos ayudarán a visualizar sus resultados de mejor forma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNGr-uNZEnQ0"
      },
      "source": [
        "import textwrap\n",
        "\n",
        "# Auxiliary function to help in the displaying of results\n",
        "def bold(text):\n",
        "  return '\\033[1m' + text + '\\033[0m'\n",
        "\n",
        "def highlight(text):\n",
        "  return '\\033[43m' + text + '\\033[0m'\n",
        "\n",
        "def display_translation(srcs, tgts, preds=None):\n",
        "    bold_end = bold('<sent_end>')\n",
        "    preds = [None] * len(srcs) if preds is None else preds\n",
        "    for idx, (src, tgt, pred) in enumerate(zip(srcs, tgts, preds), start=1):\n",
        "        print(bold(f'Sample {idx}'))\n",
        "        print(bold('Source Text:'))\n",
        "        for sent in src:\n",
        "            sent = highlight(sent) if (pred is not None) and (sent in pred.split('\\n')) else sent\n",
        "            print(textwrap.fill(sent, width=70), end=f' {bold_end}\\n')\n",
        "        print()\n",
        "\n",
        "        print(bold('Gold Standard Summarization:'))\n",
        "        # print(textwrap.fill(tgt, width=70), end=' {bold_end}\\n\\n')\n",
        "        for sent in tgt.split('<q>'):\n",
        "            print(textwrap.fill(sent, width=70), end=f' {bold_end}\\n')\n",
        "        print()\n",
        "\n",
        "        if pred is not None:\n",
        "            print(bold('Predicted Summarization:'))\n",
        "            # for sent in pred:\n",
        "            # print(textwrap.fill(pred, width=70), end=f' {bold_end}\\n\\n')\n",
        "            for sent in pred.split('\\n'):\n",
        "                print(textwrap.fill(sent, width=70), end=f' {bold_end}\\n')\n",
        "            print() \n",
        "\n",
        "        print('                 ===========================                  \\n')\n",
        "\n",
        "# Evaluation\n",
        "def _get_ngrams(n, text):\n",
        "    ngram_set = set()\n",
        "    text_length = len(text)\n",
        "    max_index_ngram_start = text_length - n\n",
        "    for i in range(max_index_ngram_start + 1):\n",
        "        ngram_set.add(tuple(text[i:i + n]))\n",
        "    return ngram_set\n",
        "\n",
        "def _block_tri(c, p):\n",
        "    tri_c = _get_ngrams(3, c.split())\n",
        "    for s in p:\n",
        "        tri_s = _get_ngrams(3, s.split())\n",
        "        if len(tri_c.intersection(tri_s))>0:\n",
        "            return True\n",
        "    return False"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6hqPsgPKhM"
      },
      "source": [
        "## Modelo de resumenes extractivo\n",
        "\n",
        "En esta sección tomaremos un modelo para generar resumenes extractivos pre-entrenado y veremos como funciona en el dataset de resumenes de noticias CNN/DailyMail.\n",
        "\n",
        "En esta actividad no entrenaremos un modelo, de todas maneras está disponible el código para que uds entrenen su propio modelo en caso de que así lo deseen.\n",
        "\n",
        "Partimos importando los paquetes que utilizaremos y utilizando las configuraciones que seteamos previamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDywD9MqqqW6"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "from models import data_loader\n",
        "from models.data_loader import load_dataset\n",
        "from models.model_builder import Summarizer\n",
        "from models.trainer import build_trainer\n",
        "\n",
        "self_trained = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge3EMmSDSut6"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "Para poder entrenar su propio modelo deben descomentar la siguientes **dos celdas** de código. \n",
        "\n",
        "Si se fijan bien, estamos configurando nuestro entrenamiento con los argumentos que le pasamos al script al llamar a `python train.py`. En base a estos argumentos pueden modificar el modelo y el entrenamiento mismo, sin embargo es importante que seteen correctamente los siguientes parámetros. Aun que si corren como está por defecto no deberían tener problemas.\n",
        "\n",
        "- `bert_data_path`: Path a los datos de entrenamiento, estos deben seguir el formato indicado en [esta sección](https://github.com/nlpyang/BertSum/#data-preparation-for-cnndailymail) del repositorio.\n",
        "- `model_path`: Path a donde serán guardados los checkpoints del entrenamiento.\n",
        "- `log_file`: Path al log del entrenamiento.\n",
        "- `batch_size`: El tamaño del batch, si tienen problemas de memoria de la GPU (no deberían en colab) pueden disminuírlo.\n",
        "- `train_steps`: Número de iteraciones del entrenamiento, el entrnemineto original consta de 50.000 iteraciones, pero pueden probar con menos. Para este caso también pueden setearlo en la variable de entorno `$TRAIN_STEPS`\n",
        "\n",
        "\n",
        "De todas maneras pueden encontrar más información en el [repositorio del proyecto](https://github.com/nlpyang/BertSum/#model-training).\n",
        "\n",
        "Es importante notar que el entrenamiento durará un par de horas en caso de que quieran realizarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW1oeOJglDsV"
      },
      "source": [
        "self_trained = True"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVhc-MgeSvY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00051d0-b9e4-4de7-bb5a-d2400186b25a"
      },
      "source": [
        "%%shell\n",
        "TRAIN_STEPS=1000 # Entrenamiento corto de prueba, originalmente 50.000\n",
        "python train.py -mode train -encoder classifier -dropout 0.1 -bert_data_path ../bert_data/cnndm \\\n",
        "                -model_path ../models/bert_classifier -lr 2e-3 -visible_gpus 0  -gpu_ranks 0 \\\n",
        "                -world_size 1 -report_every 50 -save_checkpoint_steps 1000 -batch_size 1000 \\\n",
        "               -decay_method noam -train_steps $TRAIN_STEPS -accum_count 2 -log_file ../logs/bert_classifier \\\n",
        "              -use_interval true -warmup_steps 10000\n",
        "mv ../models/bert_classifier/model_step_${TRAIN_STEPS}.pt ../models/model-self-trained.pt"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-01-03 20:51:26,911 INFO] Device ID 0\n",
            "[2021-01-03 20:51:26,911 INFO] Device cuda\n",
            "[2021-01-03 20:51:27,213 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpzuqy368v\n",
            "100% 407873900/407873900 [00:11<00:00, 34880638.90B/s]\n",
            "[2021-01-03 20:51:39,317 INFO] copying /tmp/tmpzuqy368v to cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2021-01-03 20:51:40,413 INFO] creating metadata file for ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2021-01-03 20:51:40,414 INFO] removing temp file /tmp/tmpzuqy368v\n",
            "[2021-01-03 20:51:40,465 INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2021-01-03 20:51:40,465 INFO] extracting archive file ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpfgcs6ni1\n",
            "[2021-01-03 20:51:44,615 INFO] Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-01-03 20:51:51,214 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Classifier(\n",
            "    (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-01-03 20:51:51,310 INFO] * number of parameters: 109483009\n",
            "[2021-01-03 20:51:51,310 INFO] Start training...\n",
            "[2021-01-03 20:51:51,634 INFO] Loading train dataset from ../bert_data/cnndm.train.123.bert.pt, number of examples: 2001\n",
            "[2021-01-03 20:52:05,645 INFO] Step 50/ 1000; xent: 7.44; lr: 0.0000001;  14 docs/s;     14 sec\n",
            "[2021-01-03 20:52:20,198 INFO] Step 100/ 1000; xent: 6.42; lr: 0.0000002;  14 docs/s;     29 sec\n",
            "[2021-01-03 20:52:34,804 INFO] Step 150/ 1000; xent: 5.32; lr: 0.0000003;  14 docs/s;     43 sec\n",
            "[2021-01-03 20:52:49,163 INFO] Step 200/ 1000; xent: 3.96; lr: 0.0000004;  14 docs/s;     58 sec\n",
            "[2021-01-03 20:53:03,692 INFO] Step 250/ 1000; xent: 3.53; lr: 0.0000005;  14 docs/s;     72 sec\n",
            "[2021-01-03 20:53:17,994 INFO] Step 300/ 1000; xent: 3.20; lr: 0.0000006;  15 docs/s;     86 sec\n",
            "[2021-01-03 20:53:32,266 INFO] Step 350/ 1000; xent: 3.44; lr: 0.0000007;  14 docs/s;    101 sec\n",
            "[2021-01-03 20:53:46,791 INFO] Step 400/ 1000; xent: 3.38; lr: 0.0000008;  15 docs/s;    115 sec\n",
            "[2021-01-03 20:54:01,378 INFO] Step 450/ 1000; xent: 3.35; lr: 0.0000009;  14 docs/s;    130 sec\n",
            "[2021-01-03 20:54:15,922 INFO] Step 500/ 1000; xent: 3.27; lr: 0.0000010;  15 docs/s;    144 sec\n",
            "[2021-01-03 20:54:30,314 INFO] Step 550/ 1000; xent: 3.27; lr: 0.0000011;  15 docs/s;    159 sec\n",
            "[2021-01-03 20:54:44,904 INFO] Step 600/ 1000; xent: 3.43; lr: 0.0000012;  15 docs/s;    173 sec\n",
            "[2021-01-03 20:54:59,489 INFO] Step 650/ 1000; xent: 3.29; lr: 0.0000013;  14 docs/s;    188 sec\n",
            "[2021-01-03 20:55:14,026 INFO] Step 700/ 1000; xent: 3.27; lr: 0.0000014;  14 docs/s;    202 sec\n",
            "[2021-01-03 20:55:28,401 INFO] Step 750/ 1000; xent: 3.33; lr: 0.0000015;  14 docs/s;    217 sec\n",
            "[2021-01-03 20:55:42,781 INFO] Step 800/ 1000; xent: 3.21; lr: 0.0000016;  14 docs/s;    231 sec\n",
            "[2021-01-03 20:55:57,386 INFO] Step 850/ 1000; xent: 3.34; lr: 0.0000017;  15 docs/s;    246 sec\n",
            "[2021-01-03 20:56:12,231 INFO] Step 900/ 1000; xent: 3.29; lr: 0.0000018;  15 docs/s;    261 sec\n",
            "[2021-01-03 20:56:26,926 INFO] Step 950/ 1000; xent: 3.27; lr: 0.0000019;  14 docs/s;    275 sec\n",
            "[2021-01-03 20:56:28,848 INFO] Loading train dataset from ../bert_data/cnndm.train.91.bert.pt, number of examples: 1998\n",
            "[2021-01-03 20:56:41,625 INFO] Step 1000/ 1000; xent: 3.22; lr: 0.0000020;  14 docs/s;    290 sec\n",
            "[2021-01-03 20:56:41,627 INFO] Saving checkpoint ../models/bert_classifier/model_step_1000.pt\n",
            "[2021-01-03 20:56:46,674 INFO] Loading train dataset from ../bert_data/cnndm.train.108.bert.pt, number of examples: 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cw_GQPmgsul"
      },
      "source": [
        "### Configuración de nuestra ejecución\n",
        "\n",
        "Para poder configurar correctamente nuestra ejecución utlizaremos los argumentos previamente definidos, para que estos estén ad-hoc a como está dispuesto nuestro entorno de colab. También consideraremos los argumentos que se usaron en el entrenamiento para mantenerlos igual en la creación del modelo.\n",
        "\n",
        "Estos últimos vienen en el checkpoint que tenemos del entrenamiento, así que lo leemos y actualizamos nuestros argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Ryv8W0zyvU"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eELf5vjmEs7n"
      },
      "source": [
        "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']\n",
        "\n",
        "args = Args()\n",
        "checkpoint_path = f'{args.model_path}/model.pt' if not self_trained else f'{args.model_path}/model-self-trained.pt'\n",
        "checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "opt = vars(checkpoint['opt'])\n",
        "for k in opt.keys():\n",
        "    if (k in model_flags):\n",
        "        setattr(args, k, opt[k])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV73kM9nihPx"
      },
      "source": [
        "### Datos\n",
        "\n",
        "Para poder evaluar nuestro modelo primero debemos cargar los datos de test. Además podemos aprovechar de ver la forma que tienen estos datos y hacernos una mejor idea de la tarea que está haciendo el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COG_RexEmgiJ"
      },
      "source": [
        "test_iter = data_loader.Dataloader(args, load_dataset(args, 'test', shuffle=True),\n",
        "                              args.batch_size, device,\n",
        "                              shuffle=False, is_test=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNzLuESInS-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3abbc0-03c2-4b6d-9755-7e8c5f9ab025"
      },
      "source": [
        "batch = next(iter(test_iter))\n",
        "display_translation(batch.src_str, batch.tgt_str)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mSample 1\u001b[0m\n",
            "\u001b[1mSource Text:\u001b[0m\n",
            "chinese property conglomerate dalian wanda group have formalised their\n",
            "purchase of 20 per cent of spanish champions atletico madrid . \u001b[1m<sent_end>\u001b[0m\n",
            "the purchase was formalised at an extraordinary general meeting on\n",
            "tuesday where the legal team representing wanda madrid investment\n",
            "signed off on the purchase of 726,707 shares for $ 45million ( # 32.8\n",
            "m ) . \u001b[1m<sent_end>\u001b[0m\n",
            "the deal was initially announced in january but two egms were needed\n",
            "in order to ratify the deal . \u001b[1m<sent_end>\u001b[0m\n",
            "wanda group chairman wang jianlin hopes to grow atletico 's brand in\n",
            "asia \u001b[1m<sent_end>\u001b[0m\n",
            "atletico madrid manager diego simeone speaks to the media \u001b[1m<sent_end>\u001b[0m\n",
            "wang jianlin , chairman of wanda group , said : ` wanda group is\n",
            "delighted with the possibility of contributing to the growth of\n",
            "atletico madrid and the development of its brand in asia , as well as\n",
            "being able to rely on their extraordinary experience in the training\n",
            "area , which no doubt will be very useful in the growth of base\n",
            "football in china . ' \u001b[1m<sent_end>\u001b[0m\n",
            "meanwhile , miguel angel gil marin , ceo , added : ` it 's a very\n",
            "important step for the club in their effort to build a global leading\n",
            "brand , which will help us maintain the sporting competitiveness of\n",
            "the past years and consolidate among the first clubs of football in\n",
            "the world . ' \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "\u001b[1mGold Standard Summarization:\u001b[0m\n",
            "chinese property conglomerate dalian wanda bought 20 per cent of\n",
            "atletico madrid for # 32.8 m \u001b[1m<sent_end>\u001b[0m\n",
            "deal was announced in january but ratified after two egms \u001b[1m<sent_end>\u001b[0m\n",
            "dalian wanda hope the deal will develop the club in asia \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "                 ===========================                  \n",
            "\n",
            "\u001b[1mSample 2\u001b[0m\n",
            "\u001b[1mSource Text:\u001b[0m\n",
            "( cnn ) nine british citizens were arrested in turkey on wednesday ,\n",
            "suspected of trying to cross illegally into syria , the turkish\n",
            "military said on its website . \u001b[1m<sent_end>\u001b[0m\n",
            "the group included four children -- the oldest being 10 or 11 , with\n",
            "the youngest born in 2013 , a turkish official told cnn on condition\n",
            "of anonymity . \u001b[1m<sent_end>\u001b[0m\n",
            "the nine were arrested at the turkey-syria border , the turkish\n",
            "military said . \u001b[1m<sent_end>\u001b[0m\n",
            "it did n't say why the group allegedly was trying to get into syria ,\n",
            "which has been torn by a roughly four-year war between syrian\n",
            "government forces and islamist extremist groups and other rebels . \u001b[1m<sent_end>\u001b[0m\n",
            "among the war 's combatants is isis , which has taken over parts of\n",
            "syria and iraq for what it claims is its islamic caliphate , and which\n",
            "is known to have been recruiting westerners . \u001b[1m<sent_end>\u001b[0m\n",
            "accompanying the children were three men and two women ; all nine had\n",
            "british passports , the turkish official said . \u001b[1m<sent_end>\u001b[0m\n",
            "uk police charge man with terror offenses after turkey trip \u001b[1m<sent_end>\u001b[0m\n",
            "the british foreign office said wednesday that it is aware of reports\n",
            "of the arrests and that it is seeking information about the incident\n",
            "from turkish authorities . \u001b[1m<sent_end>\u001b[0m\n",
            "cnn 's gul tuysuz reported from istanbul , and elaine ly reported from\n",
            "london . \u001b[1m<sent_end>\u001b[0m\n",
            "cnn 's jason hanna contributed to this report . \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "\u001b[1mGold Standard Summarization:\u001b[0m\n",
            "the group included four children , turkish official says \u001b[1m<sent_end>\u001b[0m\n",
            "turkish military did n't say what group 's intent was \u001b[1m<sent_end>\u001b[0m\n",
            "uk foreign office says it is trying to get information from turkish\n",
            "officials \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "                 ===========================                  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5hju-cES9hD"
      },
      "source": [
        "### Evaluación\n",
        "\n",
        "Evaluaremos nuestro modelo cualitativamente. Para esto primero debemos crear nuestro modelo y cargar los pesos que teníamos pre-entrenados.\n",
        "\n",
        "Utilizaremos la clase `Summarizer` que es a su vez un `nn.Module` de PyTorch. Esta clase integra los distintos módulos que se plantearon anteriormente para crear un resumen en base a los datos entregados. \n",
        "\n",
        "Finalmente cargamos los pesos utilizando la función `Summarizer.load_cp`, que recibe el mismo `checkpoint` que leímos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulwrAUOPmgo5"
      },
      "source": [
        "config = BertConfig.from_json_file(args.bert_config_path) # configuracion para la librería HuggingFace Transformers\n",
        "model = Summarizer(args, device, load_pretrained_bert=False, bert_config=config)\n",
        "model.load_cp(checkpoint)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGJVhnEOKs-z"
      },
      "source": [
        "Ya creado nuestro modelo, podemos ver algunos ejemplos de las predicciones que este hace. Aquí:\n",
        "\n",
        "- **Source Text:** Corresponde al documento que será resumido. En este caso al tratarse de un modelo extractivo destacamos aquí mismo las frases seleccionadas.\n",
        "- **Gold Standard Summarization:** Corresponde al resumen de referencia creado para este text, se usa a modo de \"ground truth\".\n",
        "- **Predicted Summarization:** Corresponde al resumen generado por nuestro modelo. En este caso al ser un modelo extractivo, es una selección de oraciones del texto original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HqhYVgBmgQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b076b96f-3b43-4cc4-897f-ed68be6f2239"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    batch = next(iter(test_iter))\n",
        "\n",
        "    src = batch.src\n",
        "    labels = batch.labels\n",
        "    segs = batch.segs\n",
        "    clss = batch.clss\n",
        "    mask = batch.mask\n",
        "    mask_cls = batch.mask_cls\n",
        "\n",
        "    gold = []\n",
        "    pred = []\n",
        "\n",
        "    sent_scores, mask = model(src, segs, clss, mask, mask_cls)\n",
        "\n",
        "    sent_scores = sent_scores + mask.float()\n",
        "    sent_scores = sent_scores.cpu().data.numpy()\n",
        "    selected_ids = np.argsort(-sent_scores, 1)\n",
        "\n",
        "    for i, idx in enumerate(selected_ids):\n",
        "        _pred = []\n",
        "        if len(batch.src_str[i]) == 0:\n",
        "            continue\n",
        "        for j in selected_ids[i][:len(batch.src_str[i])]:\n",
        "            if j >= len(batch.src_str[i]):\n",
        "                continue\n",
        "            candidate = batch.src_str[i][j].strip()\n",
        "            if args.block_trigram:\n",
        "                if(not _block_tri(candidate, _pred)):\n",
        "                    _pred.append(candidate)\n",
        "            else:\n",
        "                _pred.append(candidate)\n",
        "\n",
        "            if ((not args.recall_eval) and len(_pred) == 3):\n",
        "                break\n",
        "\n",
        "        _pred = '\\n'.join(_pred)\n",
        "        if (args.recall_eval):\n",
        "            _pred = ' '.join(_pred.split()[:len(batch.tgt_str[i].split())])\n",
        "\n",
        "        pred.append(_pred)\n",
        "        gold.append(batch.tgt_str[i])\n",
        "\n",
        "display_translation(batch.src_str, gold, pred)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mSample 1\u001b[0m\n",
            "\u001b[1mSource Text:\u001b[0m\n",
            "australian prime minister tony abbott thrilled players at a sydney\n",
            "australian rules football club function by skolling a beer . \u001b[1m<sent_end>\u001b[0m\n",
            "mr abbott was asked to have a drink by university of technology sydney\n",
            "bats coach simon carradous , and the prime minister happily obliged . \u001b[1m<sent_end>\u001b[0m\n",
            "\u001b[43mit appeared to take the prime minister about six seconds to down\n",
            "the schooner , as players cheered and chanted ` skol ' and ` tony '\n",
            ".\u001b[0m \u001b[1m<sent_end>\u001b[0m\n",
            "australian prime minister tony abbott thrilled players at a sydney\n",
            "australian rules football club function by skolling a beer \u001b[1m<sent_end>\u001b[0m\n",
            "it appeared to take the prime minister about six seconds to down the\n",
            "schooner , as players cheered and chanted ` skol ' and ` tony ' \u001b[1m<sent_end>\u001b[0m\n",
            "\u001b[43mmr abbott also gave a speech to the players , according to\n",
            "australian women 's weekly .\u001b[0m \u001b[1m<sent_end>\u001b[0m\n",
            "` he grabs the microphone and gives a speech , which went along the\n",
            "lines of : ` well is n't this a real treat , i 've been a rugby man\n",
            "all my life but now i finally get to hang out with some real\n",
            "footballers ' to which of course the crowd went crazy , ' mr carradous\n",
            "said . \u001b[1m<sent_end>\u001b[0m\n",
            "\u001b[43m` then he proceeds to reach down and grab a schooner and he drank\n",
            "from head-to-toe the entire schooner , dribbling little bits on his\n",
            "shirt ... he was proud as punch . '\u001b[0m \u001b[1m<sent_end>\u001b[0m\n",
            "mr abbott is not the first australian prime minister to show off his\n",
            "skolling skills , with former labor prime minister bob hawke 's\n",
            "ability well documented . \u001b[1m<sent_end>\u001b[0m\n",
            "mr abbott was asked to have a drink by university of technology sydney\n",
            "bats coach simon carradous , and the prime minister happily obliged \u001b[1m<sent_end>\u001b[0m\n",
            "` he drank the entire schooner , dribbling bits on his shirt ... he\n",
            "was proud as punch , ' a witness said \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "\u001b[1mGold Standard Summarization:\u001b[0m\n",
            "australian prime minister skols a beer with celebrating football\n",
            "players \u001b[1m<sent_end>\u001b[0m\n",
            "video emerged of tony abbott drinking the beer in six seconds \u001b[1m<sent_end>\u001b[0m\n",
            "the prime minister reportedly earlier gave a speech at the club\n",
            "function \u001b[1m<sent_end>\u001b[0m\n",
            "a crowd of 50 people surrounded mr abbott to cheer him on as he drank \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "\u001b[1mPredicted Summarization:\u001b[0m\n",
            "it appeared to take the prime minister about six seconds to down the\n",
            "schooner , as players cheered and chanted ` skol ' and ` tony ' . \u001b[1m<sent_end>\u001b[0m\n",
            "mr abbott also gave a speech to the players , according to australian\n",
            "women 's weekly . \u001b[1m<sent_end>\u001b[0m\n",
            "` then he proceeds to reach down and grab a schooner and he drank from\n",
            "head-to-toe the entire schooner , dribbling little bits on his shirt\n",
            "... he was proud as punch . ' \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "                 ===========================                  \n",
            "\n",
            "\u001b[1mSample 2\u001b[0m\n",
            "\u001b[1mSource Text:\u001b[0m\n",
            "( cnn ) misao okawa , the world 's oldest person according to guinness\n",
            "world records , has died at the age of 117 . \u001b[1m<sent_end>\u001b[0m\n",
            "\u001b[43mokawa passed away wednesday morning in osaka , japan , tadahi\n",
            "uchimura , a local official from the city told cnn .\u001b[0m \u001b[1m<sent_end>\u001b[0m\n",
            "she left behind three children , four grandchildren and six great\n",
            "grandchildren . \u001b[1m<sent_end>\u001b[0m\n",
            "okawa was born on march 5 , 1898 . \u001b[1m<sent_end>\u001b[0m\n",
            "her family ran a kimono shop in osaka , satoshi yoshioka , an employee\n",
            "at the nursing home where she had lived since 1997 told cnn . \u001b[1m<sent_end>\u001b[0m\n",
            "\" she was a person with mild character , and loved to eat so much . \u001b[1m<sent_end>\u001b[0m\n",
            "her favorite food was sushi and udon noodles , \" yoshioka said . \u001b[1m<sent_end>\u001b[0m\n",
            "\" she had eaten a lot of cake for her birthday last march 5 . \" \u001b[1m<sent_end>\u001b[0m\n",
            "\" however , in the last 10 days she stopped eating . \u001b[1m<sent_end>\u001b[0m\n",
            "\u001b[43mi think eating was her motivation to live , and when she lost it\n",
            ", she passed away . \"\u001b[0m \u001b[1m<sent_end>\u001b[0m\n",
            "\u001b[43maccording to guiness world records , the oldest person ever was\n",
            "jeanne louise calment , who died at age 122 in 1997 .\u001b[0m \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "\u001b[1mGold Standard Summarization:\u001b[0m\n",
            "misao okawa , the world 's oldest person dies at the age of 117 . \u001b[1m<sent_end>\u001b[0m\n",
            "she passed away on wednesday morning in japan . \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "\u001b[1mPredicted Summarization:\u001b[0m\n",
            "i think eating was her motivation to live , and when she lost it , she\n",
            "passed away . \" \u001b[1m<sent_end>\u001b[0m\n",
            "according to guiness world records , the oldest person ever was jeanne\n",
            "louise calment , who died at age 122 in 1997 . \u001b[1m<sent_end>\u001b[0m\n",
            "okawa passed away wednesday morning in osaka , japan , tadahi uchimura\n",
            ", a local official from the city told cnn . \u001b[1m<sent_end>\u001b[0m\n",
            "\n",
            "                 ===========================                  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ3WoiKWYMAz"
      },
      "source": [
        "### Actividad 1\n",
        "\n",
        "Ejecute el notebook completo incluyendo un entrenamiento de tan solo 1.000 iteraciones.\n",
        "\n",
        "**Ayuda:** Debe seguir las instrucciones detalladas en la sección [Entrenamiento](#scrollTo=Ge3EMmSDSut6) y continuar la ejecución normalmente.\n",
        "\n",
        "**Importante:** Para la entrega de esta actividad el notebook debe tener incluída la ejecución del entrenamiento para obtener puntaje."
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio_2_Redes_Convolucionales_Diplomado_IA_FranciscoMena.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7b42ef04c0047f98e61e28d3bac7d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_611c8dd6f5f84609b53b2de26bb14c2c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_563a4017edda47b9ad295d26c33cdba5",
              "IPY_MODEL_fd8fa0127a5e4a5aa4b9ec901c62b6d2"
            ]
          }
        },
        "611c8dd6f5f84609b53b2de26bb14c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "563a4017edda47b9ad295d26c33cdba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_91185e0678894f919416ddb1af037d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3180775a09e4bf09e9ccf4bf2588100"
          }
        },
        "fd8fa0127a5e4a5aa4b9ec901c62b6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41c5b240be864c60802aca248ea00614",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1057602.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_385f2a0078684bfaa158c64577fa2847"
          }
        },
        "91185e0678894f919416ddb1af037d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3180775a09e4bf09e9ccf4bf2588100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41c5b240be864c60802aca248ea00614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "385f2a0078684bfaa158c64577fa2847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98725b795e6a4313a213ed6d94df963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb26f330e0384a68a4402a848af3778a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e65a1cfdbb54111b4b6a2c7b0536d7b",
              "IPY_MODEL_0ffb3b339239455cad0761af02cc2543"
            ]
          }
        },
        "fb26f330e0384a68a4402a848af3778a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e65a1cfdbb54111b4b6a2c7b0536d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_831f3b33dd1d4dae8c512d0c0b7714fa",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd96c935ef7c4896a56de3f5c4d9f1b8"
          }
        },
        "0ffb3b339239455cad0761af02cc2543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8cdbf6332ba470e8cc311a164372691",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5572bcca31c2431485a061648be497cc"
          }
        },
        "831f3b33dd1d4dae8c512d0c0b7714fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd96c935ef7c4896a56de3f5c4d9f1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8cdbf6332ba470e8cc311a164372691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5572bcca31c2431485a061648be497cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "174ca99f02f243b5937fc15c6bd5aa69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e26376e6475c417ab0040e5a04d90e7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20b5a356d7174842b6363876a57b7915",
              "IPY_MODEL_7fb7694f9f29451e8d1421031c76963f"
            ]
          }
        },
        "e26376e6475c417ab0040e5a04d90e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20b5a356d7174842b6363876a57b7915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9e7fadf908c465aaf3edd81a1e5ceaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd8273bb77fd4ec383d20a95125a692a"
          }
        },
        "7fb7694f9f29451e8d1421031c76963f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75c3e3f1458f4fbf909024c2d7746f28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:01&lt;00:00, 1530466.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82d9ed73bef94b878172d2838edac6bd"
          }
        },
        "b9e7fadf908c465aaf3edd81a1e5ceaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd8273bb77fd4ec383d20a95125a692a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75c3e3f1458f4fbf909024c2d7746f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82d9ed73bef94b878172d2838edac6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a57d64a6cd8544d89a8434d998a6fa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1f172893ae64bf2b96e784565f50785",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4785dbb7936d474a85726c42d0a00db0",
              "IPY_MODEL_82951eb7fd08459c8d27628df73e331a"
            ]
          }
        },
        "a1f172893ae64bf2b96e784565f50785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4785dbb7936d474a85726c42d0a00db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0d6463239624d2ea0136142b5d8573c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6521283e806249c496a5a366cecc5282"
          }
        },
        "82951eb7fd08459c8d27628df73e331a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8a7a456d8164cf4b7a4e76fe5cee8d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 21219.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f7372ac218f41d986cc06e056b99dc2"
          }
        },
        "b0d6463239624d2ea0136142b5d8573c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6521283e806249c496a5a366cecc5282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8a7a456d8164cf4b7a4e76fe5cee8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f7372ac218f41d986cc06e056b99dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a93a1220aa643d2bf0493cea706733f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0f2f1f22eb149f39c2b6711053ea489",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4b9d812925348758736e8e23708e61b",
              "IPY_MODEL_e724ad7d3639474fb60c5f248da57ada"
            ]
          }
        },
        "a0f2f1f22eb149f39c2b6711053ea489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4b9d812925348758736e8e23708e61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfc9079cfd484d6c84451e9f79d67915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c4df75ab97747d7ac6e0ed64e110648"
          }
        },
        "e724ad7d3639474fb60c5f248da57ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3daf2adaff44c3dac904b66c7381ef3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:17&lt;00:00, 38641693.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78c4b6acd6d44f08a0725b867bbc599b"
          }
        },
        "bfc9079cfd484d6c84451e9f79d67915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c4df75ab97747d7ac6e0ed64e110648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3daf2adaff44c3dac904b66c7381ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78c4b6acd6d44f08a0725b867bbc599b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29c7d49265ab46729d36817384d51ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bbed9c126cf4251b749313941252afd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75e4e0a4470041d2ba76534e2f4892fc",
              "IPY_MODEL_e0a5bbcf2a0f4afda22121429ef9a527"
            ]
          }
        },
        "1bbed9c126cf4251b749313941252afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75e4e0a4470041d2ba76534e2f4892fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2634b54a3c1b4f499ab08a36e68c6c03",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f9dc304981c433b9c4434f30d5bf5b7"
          }
        },
        "e0a5bbcf2a0f4afda22121429ef9a527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_411c298ba5724bdb894981f258a2b2c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [23:43&lt;00:00, 172kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d2048bad8ff43b58b3e2974ba6ada36"
          }
        },
        "2634b54a3c1b4f499ab08a36e68c6c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f9dc304981c433b9c4434f30d5bf5b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "411c298ba5724bdb894981f258a2b2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d2048bad8ff43b58b3e2974ba6ada36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzO98wJgjmOd"
      },
      "source": [
        "# Laboratorio 2 - Redes Convolucionales - Diplomado Inteligencia Artificial UC\n",
        "\n",
        "**IMPORTANTE: habrÃ¡ un bonus de 1 dÃ©cima para todos aquellos alumnos/as que muestren buen orden en sus respuestas (esto aplica a legibilidad de cÃ³digo, buena redacciÃ³n, formalidad, organizaciÃ³n del jupyter notebook, seguimiento de instrucciones, etc). El criterio lo pondrÃ¡ cada ayudante corrector. La nota mÃ¡xima obtenible en el laboratorio es 7.0.**\n",
        "\n",
        "En este laboratorio nos interiorizaremos en cÃ³mo funciona Pytorch (https://pytorch.org/), el framework de Facebook para implementar Redes Neuronales Profundas.\n",
        "\n",
        "Vamos a ver varias partes distintas del flujo de entrenamiento, desde cÃ³mo cargamos los datos, cÃ³mo creamos redes, cÃ³mo las entrenamos y cÃ³mo validamos su rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og-s3Wv2oEOe"
      },
      "source": [
        "## El Tensor: la unidad fundamental.\n",
        "\n",
        "Los tensores son el elemento fundamental con que trabajarÃ¡n nuestras redes profundas. Un tensor es simplemente una matriz de n-dimensiones. \n",
        "\n",
        "* En **imÃ¡genes**, usamos tensores de 4 dimensiones: 3 dimensiones (alto, ancho y color) mÃ¡s una cuarta dimensiÃ³n asociada a los elementos del batch.\n",
        "\n",
        "* Cuando trabajamos con **texto** podemos tener tensores en 3 dimensiones (dimensiÃ³n de embedding, palabras y batch).\n",
        "\n",
        "* Si trabajamos con **videos** tenemos que agregar otra dimensiÃ³n para el tiempo. En fin, todos estos datos distintos al final se representan como matrices de nÃºmeros en 3, 4 Ã³ 5 dimensiones distintas.\n",
        "\n",
        "Pytorch representa los tensores via la clase torch.Tensor. Todas las redes neuronales que hagamos requieren tensores para poder trabajar. Nuestros datasets no servirÃ¡n de nada si no podemos transformarlos en tensores que podamos ocupar con nuestras redes. Si han trabajado con *ndarray* de Numpy la forma de ocuparlos es muy similar. Veamos un tensor de ejemplo de 3 dimensiones: ancho, alto y batch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5omMrW5bUS",
        "outputId": "2ac7c846-849e-4604-f589-3b452fd92405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "batch_dim = 5\n",
        "alto = 2\n",
        "ancho = 3\n",
        "tensor_ejemplo = torch.randn((batch_dim, ancho, alto)).float() # Tensor aleatorio\n",
        "print(\"El tensor es: {}\\n\".format(tensor_ejemplo))\n",
        "print(\"La forma del tensor es: {}\".format(tensor_ejemplo.shape))\n",
        "print(\"El tipo del tensor es: {}\".format(type(tensor_ejemplo)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El tensor es: tensor([[[ 0.0628, -0.9507],\n",
            "         [-1.2270,  0.4503],\n",
            "         [ 0.3438,  1.0220]],\n",
            "\n",
            "        [[-0.0261,  0.6921],\n",
            "         [ 0.0907,  0.8105],\n",
            "         [ 0.6341, -1.4089]],\n",
            "\n",
            "        [[ 0.2022,  0.9402],\n",
            "         [-2.2096,  1.0981],\n",
            "         [ 1.0203, -0.7037]],\n",
            "\n",
            "        [[-0.1311,  0.8031],\n",
            "         [-0.6545, -0.3806],\n",
            "         [-0.9115, -0.3599]],\n",
            "\n",
            "        [[ 0.4298,  0.6213],\n",
            "         [-0.4998,  1.6038],\n",
            "         [-1.3326,  1.4618]]])\n",
            "\n",
            "La forma del tensor es: torch.Size([5, 3, 2])\n",
            "El tipo del tensor es: <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHpZ99Rvjgte"
      },
      "source": [
        "Crear un tensor desde un arreglo de Python es sencillo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn84KtqwjObX",
        "outputId": "f35487ab-a15f-4a82-d5c1-1e23c7cd458f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arreglo = [[1, 2, 3], [4, 5, 6]]\n",
        "tensor_desde_arreglo = torch.tensor(arreglo)\n",
        "print(tensor_desde_arreglo, tensor_desde_arreglo.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]]) torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwE7bG-56rx6"
      },
      "source": [
        "Uno trabaja los tensores de la misma manera que cualquier otra variable numÃ©rica en Python. Se pueden, sumar y restar sin problema. La multiplicaciÃ³n por escalares no supone problema y la multiplicaciÃ³n de tensores tambiÃ©n estÃ¡ soportada.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH-U3PPi7az0",
        "outputId": "bd5c28b0-f3a0-4a4d-c91b-49b1a98db545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor_1 = torch.randn((1,2,3))\n",
        "tensor_2 = torch.randn((1,2,3))\n",
        "\n",
        "tensor_3 = tensor_1 + tensor_2\n",
        "\n",
        "print(tensor_1)\n",
        "print(tensor_2)\n",
        "print(tensor_3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.4805, -1.0274, -0.4928],\n",
            "         [-0.2328, -0.5994, -0.4366]]])\n",
            "tensor([[[-0.3093,  0.3467,  1.8701],\n",
            "         [-0.1841, -0.7706, -0.3375]]])\n",
            "tensor([[[ 0.1712, -0.6807,  1.3773],\n",
            "         [-0.4169, -1.3700, -0.7742]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoNoKKFATdEv"
      },
      "source": [
        "Podemos indexarlos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OUPry8-TcGX",
        "outputId": "e5526084-348b-4850-94cd-7905e766456c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor_indexado = tensor_1[:,:,:2]\n",
        "print(tensor_indexado, tensor_indexado.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.4805, -1.0274],\n",
            "         [-0.2328, -0.5994]]]) torch.Size([1, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGAdf1Zz7a8T"
      },
      "source": [
        "#### Sobre la dimensiÃ³n batch\n",
        "\n",
        "La dimensiÃ³n de batch es importante pues es la que nos permite poder entrenar de forma paralela en nuestras GPUs. El estÃ¡ndar de Pytorch es que Ã©sta es la primera dimensiÃ³n de nuestros tensores siempre. Aunque solo evaluar un elemento en nuestra red, este debe tener una dimensiÃ³n de batch en su primer lugar o sino no funcionarÃ¡. TambiÃ©n es necesario mencionar que Pytorch espera siempre que la dimensiÃ³n del canal vaya antes que las dimensiones de ancho y alto en imÃ¡genes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX3ER77PS_H_"
      },
      "source": [
        "### Sobre el dispositivo asociado\n",
        "\n",
        "Los tensores son procesados por la CPU o por una GPU. Como quizÃ¡s hemos escuchado antes, sabemos que parte de la explosiÃ³n de Deep Learning viene por la disponibilidad de GPUs cada vez mÃ¡s poderosas. Para poder trabajar en GPU un tensor tenemos que hacer lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ln8Wq3wURfu"
      },
      "source": [
        "tensor_nuevo = torch.randn((1,2,3))     # Por defecto el tensor estÃ¡ en CPU\n",
        "tensor_nuevo_gpu = tensor_nuevo.cuda()  # CreÃ© una copia de tensor_nuevo en GPU!\n",
        "otra_forma = tensor_nuevo.to('cuda')    # CreÃ© otra copia de tensor_nuevo en GPU!"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JmfrUSLkF2o"
      },
      "source": [
        "## DefiniciÃ³n del Modelo\n",
        "Como vimos en el laboratorio pasado, definir un modelo de aprendizaje profundo consiste en definir una nueva clase que herede de torch.nn.Module.\n",
        "\n",
        "Esta clase debe implementar dos mÃ©todos para funcionar como un modelo vÃ¡lido en Pytorch:\n",
        "\n",
        "* MÃ©todo \\_\\_init\\_\\_(self): el constructor de la clase. AquÃ­ es donde usualmente definiremos todos los elementos arquitÃ©ctonicos de nuestra red. AquÃ­ definiremos que capas tendrÃ¡, quÃ© funciones de activaciÃ³n, funciones de pooling, etc.\n",
        "\n",
        "* MÃ©todo forward(self, input): define las conexiones entre capas del modelo, o cÃ³mo debe fluir la informaciÃ³n que entra en Ã©l. Debe retornar un tensor.\n",
        "\n",
        "### Elementos arquitectÃ³nicos\n",
        "\n",
        "Todos estos elementos estÃ¡n definidos en el paquete torch.nn (de Neural Networks). Todos derivan de la clase torch.nn.Module.\n",
        "\n",
        "* **Linear:** capa lineal. Toma como parÃ¡metros las cantidades de neuronas de entrada y de salida.\n",
        "* **Conv1d, Conv2d, Conv3d**: capas convolucionales de 1, 2 y 3 dimensiones respectivamente. Definidas por el tamaÃ±o del kernel que ocupan, el *stride*, filtros de entrada y de salida.\n",
        "* **ReLU**: funciÃ³n de activaciÃ³n. No tiene parÃ¡metros.\n",
        "* **Sigmoid**: funciÃ³n de activaciÃ³n. No tiene parÃ¡metros.\n",
        "* **Softmax**: capa que transforma el output en una distribuciÃ³n de probabilidad. ParÃ¡metro es sobre la o las dimensiones que se aplica.\n",
        "* **MaxPool1d, MaxPool2d, MaxPool3d**: Funciones de pooling en 1,2 y 3 dimensiones respectivamente.\n",
        "* **Dropout**: capa que deja en 0 neuronas con probabilidad $p$. ParÃ¡metro: $p$.\n",
        "* **BatchNorm2d**: capa que normaliza el input de acuerdo a una media y varianza aprendidas. \n",
        "* **Sequential**: es un agrupador de MÃ³dulos. Se encarga de que la informaciÃ³n fluya de forma secuencial entre los mÃ³dulos que contiene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6fz8KLbXfXJ",
        "outputId": "b517f29f-ee82-43bb-bf55-c467fad59998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU, Sigmoid, Sequential, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
        "\n",
        "tensor_prueba = torch.randn((3, 5))\n",
        "\n",
        "print(tensor_prueba, tensor_prueba.shape)\n",
        "\n",
        "# Capa Lineal que va de 5 dimensiones a 8\n",
        "capa_lineal = Linear(5, 8)\n",
        "tensor_nuevo = capa_lineal(tensor_prueba)\n",
        "print(\"Tensor despuÃ©s de Capa Lineal:\")\n",
        "print(tensor_nuevo, tensor_nuevo.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]]) torch.Size([3, 5])\n",
            "Tensor despuÃ©s de Capa Lineal:\n",
            "tensor([[-1.4172,  0.2860, -0.4144,  0.4446, -1.1229, -0.3033,  0.2553, -0.2322],\n",
            "        [-0.6428,  0.0117, -0.0732,  0.5970,  0.4639, -0.0060, -0.2565, -0.4994],\n",
            "        [-0.6700,  0.3882, -0.2621,  0.1579, -1.1278, -0.8477,  0.7021,  0.3488]],\n",
            "       grad_fn=<AddmmBackward>) torch.Size([3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6q_9qzcFiP",
        "outputId": "8a1c58a4-7455-45db-d2f9-d27b15d1aa8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Funciones de ActivaciÃ³n\n",
        "# ReLU\n",
        "relu = ReLU()\n",
        "print(\"Antes de ReLU: \")\n",
        "print(tensor_prueba)\n",
        "print(\"DespuÃ©s de ReLU: \")\n",
        "print(relu(tensor_prueba))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de ReLU: \n",
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]])\n",
            "DespuÃ©s de ReLU: \n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.2673, 0.0000],\n",
            "        [0.5121, 0.0000, 0.0000, 0.0000, 0.7996],\n",
            "        [0.0000, 0.0000, 1.5817, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL3sBxCbcLty",
        "outputId": "31b58fb8-85ff-45ed-9894-fc262e8ea2b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sigmoid\n",
        "s = Sigmoid()\n",
        "print(\"Antes de Sigmoid: \")\n",
        "print(tensor_prueba)\n",
        "print(\"DespuÃ©s de Sigmoid: \")\n",
        "print(s(tensor_prueba))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de Sigmoid: \n",
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]])\n",
            "DespuÃ©s de Sigmoid: \n",
            "tensor([[0.2156, 0.1622, 0.4712, 0.5664, 0.3955],\n",
            "        [0.6253, 0.2966, 0.2280, 0.4049, 0.6899],\n",
            "        [0.2885, 0.3764, 0.8294, 0.4894, 0.4474]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pRxMMlacFpR",
        "outputId": "ce60b294-672e-4fa6-c99b-1d4a6144fe13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Softmax\n",
        "soft = Softmax(dim=1)\n",
        "print(\"Antes de Softmax: \")\n",
        "print(tensor_prueba)\n",
        "print(\"DespuÃ©s de Softmax: \")\n",
        "soft_tensor = soft(tensor_prueba)\n",
        "print(soft_tensor)\n",
        "print(soft_tensor.sum(dim=1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de Softmax: \n",
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]])\n",
            "DespuÃ©s de Softmax: \n",
            "tensor([[0.0828, 0.0583, 0.2684, 0.3934, 0.1970],\n",
            "        [0.3154, 0.0797, 0.0558, 0.1286, 0.4205],\n",
            "        [0.0531, 0.0790, 0.6365, 0.1254, 0.1060]])\n",
            "tensor([1.0000, 1.0000, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCDkA0IFcFwG",
        "outputId": "3a746e8d-3a07-4c22-af2c-663685e9527c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sequential\n",
        "# Unamos pasos\n",
        "seq = Sequential(capa_lineal, relu, soft)\n",
        "tensor_final = seq(tensor_prueba)\n",
        "print(\"Aplicando Sequential: \")\n",
        "print(tensor_final, tensor_final.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aplicando Sequential: \n",
            "tensor([[0.1089, 0.1450, 0.1089, 0.1699, 0.1089, 0.1089, 0.1406, 0.1089],\n",
            "        [0.1062, 0.1074, 0.1062, 0.1929, 0.1688, 0.1062, 0.1062, 0.1062],\n",
            "        [0.0992, 0.1463, 0.0992, 0.1162, 0.0992, 0.0992, 0.2002, 0.1406]],\n",
            "       grad_fn=<SoftmaxBackward>) torch.Size([3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kImxDES0Zek6",
        "outputId": "99d77dd0-569e-48a4-9105-7c47224df1f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Dropout\n",
        "drop = Dropout(p=0.15) # con probabilidad de dejar en 0 de 0.15.\n",
        "tensor_dropout = drop(tensor_prueba)\n",
        "print(tensor_dropout)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.5192, -1.9319, -0.1355,  0.3144, -0.0000],\n",
            "        [ 0.0000, -1.0160, -1.4346, -0.0000,  0.9407],\n",
            "        [-1.0618, -0.5938,  1.8608, -0.0501, -0.2485]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSpvnCsuZwQo",
        "outputId": "bf01e07e-79d8-4d47-ef7a-516bca423f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batch Normalization 1d\n",
        "tensor_lineal = 20*torch.randn((3, 5))  # Una imagen con varianza alta\n",
        "bn = BatchNorm1d(5, momentum=None)                             # 3 es el nÃºmero de canales\n",
        "\n",
        "\n",
        "print(\"La media de los vectores originales por dimensiÃ³n es: {}\".format(tensor_lineal.mean(dim=[0])))   \n",
        "print(\"La varianza de los vectores originales por dimensiÃ³n es: {}\".format(tensor_lineal.var(dim=[0], unbiased=False)))\n",
        "print(\"Las medias por dimensiÃ³n de BN inicialmente son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por dimensiÃ³n de BN inicialmente son: {}\".format(bn.running_var))\n",
        "\n",
        "tensor_bn = bn(tensor_lineal)\n",
        "\n",
        "print(\"La media por dimensiÃ³n del resultado es: {}\".format(tensor_bn.mean(dim=[0])))   \n",
        "print(\"La varianza por dimensiÃ³n del resultado es: {}\".format(tensor_bn.var(dim=[0], unbiased=False)))\n",
        "print(\"Las medias por dimensiÃ³n de BN ahora son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por dimensiÃ³n de BN ahora son: {}\".format(bn.running_var))  \n",
        "\n",
        "for n, p in bn.named_parameters():\n",
        "    print(n,p)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de los vectores originales por dimensiÃ³n es: tensor([ 7.0683,  8.7154,  8.1161, 22.8584, -4.9177])\n",
            "La varianza de los vectores originales por dimensiÃ³n es: tensor([436.5844, 427.5392, 706.6785, 271.8681, 539.7061])\n",
            "Las medias por dimensiÃ³n de BN inicialmente son: tensor([0., 0., 0., 0., 0.])\n",
            "Las varianzas por dimensiÃ³n de BN inicialmente son: tensor([1., 1., 1., 1., 1.])\n",
            "La media por dimensiÃ³n del resultado es: tensor([-9.9341e-09,  0.0000e+00,  0.0000e+00, -3.9736e-08,  0.0000e+00],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "La varianza por dimensiÃ³n del resultado es: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<VarBackward1>)\n",
            "Las medias por dimensiÃ³n de BN ahora son: tensor([ 7.0683,  8.7154,  8.1161, 22.8584, -4.9177])\n",
            "Las varianzas por dimensiÃ³n de BN ahora son: tensor([ 654.8766,  641.3088, 1060.0178,  407.8022,  809.5591])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTjNvAWfocwY",
        "outputId": "43397bb2-0b90-4968-b27d-9868d29b6805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batch Normalization 2d\n",
        "tensor_imagenes = 20*torch.randn((3, 3, 2, 2))  # Una imagen con varianza alta\n",
        "bn = BatchNorm2d(3, momentum = None, eps=0.0)                             # 3 es el nÃºmero de canales\n",
        "\n",
        "\n",
        "print(\"La media de las imÃ¡genes originales por canal es: {}\".format(tensor_imagenes.mean(dim=[0,2,3])))   \n",
        "print(\"La varianza de las imÃ¡genes originales por canal es: {}\".format(tensor_imagenes.var(dim=[0,2,3], unbiased=False)))\n",
        "print(\"Las medias por canal de BN inicialmente son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por canal de BN inicialmente son: {}\".format(bn.running_var))\n",
        "\n",
        "tensor_bn = bn(tensor_imagenes)\n",
        "\n",
        "print(\"La media por canal es: {}\".format(tensor_bn.mean(dim=[0,2,3])))   \n",
        "print(\"La varianza por canal es: {}\".format(tensor_bn.var(dim=[0,2,3], unbiased=False)))\n",
        "print(\"Las medias por canal de BN ahora son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por canal de BN ahora son: {}\".format(bn.running_var))\n",
        "\n",
        "for n, p in bn.named_parameters():\n",
        "    print(n,p)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de las imÃ¡genes originales por canal es: tensor([ 7.9804,  2.7427, -1.3530])\n",
            "La varianza de las imÃ¡genes originales por canal es: tensor([446.7048, 501.9675, 587.4157])\n",
            "Las medias por canal de BN inicialmente son: tensor([0., 0., 0.])\n",
            "Las varianzas por canal de BN inicialmente son: tensor([1., 1., 1.])\n",
            "La media por canal es: tensor([-2.2352e-08,  4.9671e-09,  1.9868e-08], grad_fn=<MeanBackward1>)\n",
            "La varianza por canal es: tensor([1., 1., 1.], grad_fn=<VarBackward1>)\n",
            "Las medias por canal de BN ahora son: tensor([ 7.9804,  2.7427, -1.3530])\n",
            "Las varianzas por canal de BN ahora son: tensor([487.3143, 547.6009, 640.8171])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNvplXz5xkUZ"
      },
      "source": [
        "### Revisitando AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGXdKoKfxkaa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su mÃ³dulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquÃ­ armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: ConvoluciÃ³n, Pooling y ActivaciÃ³n.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la ConvoluciÃ³n\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # TamaÃ±o de la ConvoluciÃ³n\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # CuÃ¡ntos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # ActivaciÃ³n                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # AquÃ­ armamos cÃ³mo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrÃ¡s de la\n",
        "                                 # otra. No todas las redes son asÃ­.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSvQo9EFkFz2"
      },
      "source": [
        "## Manejo de Datos\n",
        "\n",
        "En un problema normal de Machine Learning, usualmente la gestiÃ³n de datos no era muy importante dado que los datasets en general son pequeÃ±os. Sin embargo, dados los volÃºmenes de datos que requieren los modelos de aprendizaje profundo, se vuelve difÃ­cil mantener los datos en memoria. Por esto, se requiere consumirlos de manera parcelada para poder ocuparlos con las restricciones de hardware que tenemos.\n",
        "\n",
        "Pytorch resuelve el problema mediante dos abstracciones: las clases *Dataset* y *DataLoader*. \n",
        "\n",
        "* La clase *Dataset* trabaja como una interfaz sencilla para acceder nuestros datos fÃ­sicos.\n",
        "* La clase *DataLoader* se encarga de agrupar los elementos de la clase *Dataset* en *batches* para pasarle a nuestro modelo.\n",
        "\n",
        "Usualmente, el mayor trabajo reside en definir una clase Dataset apropiada para nuestro conjunto de datos. Por suerte, si queremos trabajar con ciertos conjuntos de datos estÃ¡ndar, Pytorch ya tiene definido estos datasets por nosotros.\n",
        "\n",
        "Si no, lo Ãºnico que tenemos que hacer es definir una clase que herede de torch.utils.data.Dataset y que implemente dos mÃ©todos:\n",
        "\n",
        "* \\_\\_len(self)\\_\\_: mÃ©todo que devuelva el tamaÃ±o total del dataset.\n",
        "* \\_\\_getitem\\_\\_(self, index): mÃ©todo que entregue un elemento particular del dataset dado un Ã­ndice (index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQI4FW7tm5Kq"
      },
      "source": [
        "### Usar Datasets predefinidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUu0A4sIm56x",
        "outputId": "ab704d5a-3799-4df9-d655-f14a59a7f706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486,
          "referenced_widgets": [
            "f7b42ef04c0047f98e61e28d3bac7d24",
            "611c8dd6f5f84609b53b2de26bb14c2c",
            "563a4017edda47b9ad295d26c33cdba5",
            "fd8fa0127a5e4a5aa4b9ec901c62b6d2",
            "91185e0678894f919416ddb1af037d61",
            "b3180775a09e4bf09e9ccf4bf2588100",
            "41c5b240be864c60802aca248ea00614",
            "385f2a0078684bfaa158c64577fa2847",
            "98725b795e6a4313a213ed6d94df963d",
            "fb26f330e0384a68a4402a848af3778a",
            "4e65a1cfdbb54111b4b6a2c7b0536d7b",
            "0ffb3b339239455cad0761af02cc2543",
            "831f3b33dd1d4dae8c512d0c0b7714fa",
            "cd96c935ef7c4896a56de3f5c4d9f1b8",
            "c8cdbf6332ba470e8cc311a164372691",
            "5572bcca31c2431485a061648be497cc",
            "174ca99f02f243b5937fc15c6bd5aa69",
            "e26376e6475c417ab0040e5a04d90e7d",
            "20b5a356d7174842b6363876a57b7915",
            "7fb7694f9f29451e8d1421031c76963f",
            "b9e7fadf908c465aaf3edd81a1e5ceaf",
            "bd8273bb77fd4ec383d20a95125a692a",
            "75c3e3f1458f4fbf909024c2d7746f28",
            "82d9ed73bef94b878172d2838edac6bd",
            "a57d64a6cd8544d89a8434d998a6fa3b",
            "a1f172893ae64bf2b96e784565f50785",
            "4785dbb7936d474a85726c42d0a00db0",
            "82951eb7fd08459c8d27628df73e331a",
            "b0d6463239624d2ea0136142b5d8573c",
            "6521283e806249c496a5a366cecc5282",
            "e8a7a456d8164cf4b7a4e76fe5cee8d9",
            "6f7372ac218f41d986cc06e056b99dc2",
            "2a93a1220aa643d2bf0493cea706733f",
            "a0f2f1f22eb149f39c2b6711053ea489",
            "f4b9d812925348758736e8e23708e61b",
            "e724ad7d3639474fb60c5f248da57ada",
            "bfc9079cfd484d6c84451e9f79d67915",
            "6c4df75ab97747d7ac6e0ed64e110648",
            "e3daf2adaff44c3dac904b66c7381ef3",
            "78c4b6acd6d44f08a0725b867bbc599b"
          ]
        }
      },
      "source": [
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True)\n",
        "cifar = CIFAR10(root=\".\", train=True, download=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7b42ef04c0047f98e61e28d3bac7d24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98725b795e6a4313a213ed6d94df963d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "174ca99f02f243b5937fc15c6bd5aa69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a57d64a6cd8544d89a8434d998a6fa3b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a93a1220aa643d2bf0493cea706733f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Pu0YgnhTNZ"
      },
      "source": [
        "Veamos un ejemplo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcacrRSMhTUs",
        "outputId": "e5504e4b-2637-4cb2-fe0b-8d1ed9e00048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7FC93406F828>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U2JVToqhpas"
      },
      "source": [
        "Vemos que contiene dos elementos: el primero es una imagen en formato PIL y el segundo es la clase asociada a esa imagen (nuestro target o ground truth). La imagen se ve asÃ­:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuDtFpjheKp",
        "outputId": "51242a79-7fa7-4df2-996a-7b5e23af0ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from IPython.display import display     # Esto no es Pytorch, es solo una librerÃ­a\n",
        "                                        # para desplegar imÃ¡genes en Colab.\n",
        "display(mnist_train[0][0])\n",
        "display(cifar[0][0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FC930129710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FC930058BE0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJPBWG9Qh9CD"
      },
      "source": [
        "Sin embargo, una imagen en formato PIL no es un tensor de Pytorch. Tenemos que hacer algo para transformarla! Por suerte para nosotros, Pytorch nos ofrece transformaciones estÃ¡ndar para imÃ¡genes, en particular, una para transformar imÃ¡genes PIL a tensores. Veamos cÃ³mo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw_qKilQiTHk"
      },
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True, transform=ToTensor())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M-kU58jibL9",
        "outputId": "8556ab8e-9d70-44de-b6a8-88f82bf12b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train[9]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.7451,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5608, 0.9686, 0.6000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9686, 0.9490, 0.3373,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9882, 0.7333, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.7255, 0.0706, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.3490, 0.9255, 0.8510, 0.1843, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8471, 0.9922, 0.2353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.8314, 1.0000, 0.3176, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.9882, 0.2667, 0.0000,\n",
              "           0.0000, 0.0000, 0.1882, 0.9490, 0.9922, 0.3490, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5137, 0.9843, 0.8314, 0.0824, 0.0000,\n",
              "           0.0000, 0.0431, 0.6549, 0.9882, 0.7725, 0.0196, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1137, 0.9098, 0.9686, 0.2471, 0.0000, 0.0000,\n",
              "           0.0000, 0.6000, 0.9882, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1765, 0.8588, 0.9882, 0.5608, 0.0000, 0.0000, 0.0000,\n",
              "           0.4549, 0.9765, 0.9882, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
              "           0.3765, 0.9922, 1.0000, 0.9922, 0.7843, 0.4784, 0.0275, 0.0980,\n",
              "           0.7882, 0.9804, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608,\n",
              "           0.9882, 0.9882, 0.9922, 0.8510, 0.9882, 0.9882, 0.7843, 0.8902,\n",
              "           0.9882, 0.9059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9843,\n",
              "           0.9686, 0.9059, 0.2549, 0.1882, 0.7412, 0.9882, 0.9882, 0.9922,\n",
              "           0.9882, 0.9843, 0.8902, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8667,\n",
              "           0.3843, 0.0000, 0.0000, 0.0000, 0.1647, 0.7686, 0.9882, 0.9922,\n",
              "           0.9882, 0.9882, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.1137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.9373, 0.9882, 0.3373,\n",
              "           0.1647, 0.1647, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0588, 0.5804, 0.9922, 0.8549, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4745, 0.9882, 0.9059, 0.1098, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1216, 0.8667, 0.9843, 0.5059, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.8549, 0.9882, 0.6275, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4784, 0.9882, 0.3216, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]), 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TgMYxJCifaf"
      },
      "source": [
        "Ahora nuestro Dataset automÃ¡ticamente transforma las imÃ¡genes PIL a tensores de Pytorch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRFZkdKJUOjP"
      },
      "source": [
        "### Crear un Dataset de ejemplo\n",
        "\n",
        "Vamos a crear un Dataset para el conjunto de datos Flowers que vimos el laboratorio pasado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSJdFURr_B8",
        "outputId": "a78a14e4-774e-4e6f-a2b6-9ae45c1d727b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/q53g4cmpnvzhnhi/flowers.tar.gz -q --show-progress\n",
        "!tar -xzf flowers.tar.gz"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flowers.tar.gz      100%[===================>] 328.99M  73.0MB/s    in 4.6s    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FXcvQ5VUOtH"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "class Flowers(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.imagenes = []       # Vincula el indice con un nombre de archivo\n",
        "        self.imgs_to_class = []  # Vincula el indice con una clase\n",
        "        self.imagenes, self.imgs_to_class = self.armar_indices(root)\n",
        "    \n",
        "    def armar_indices(self, root):\n",
        "        n_classes = len(listdir(root)) # El nÃºmero de carpetas es la cantidad de clases\n",
        "        contador = 0\n",
        "        lista_imagenes = []\n",
        "        imgs_to_class = []\n",
        "        for clase in listdir(root):\n",
        "            directorio = join(root, clase)\n",
        "            for archivo in listdir(directorio):\n",
        "                lista_imagenes.append(archivo)\n",
        "                contador+=1\n",
        "                imgs_to_class.append(int(clase))\n",
        "\n",
        "        return lista_imagenes, imgs_to_class\n",
        "\n",
        "    def obtener_imagen(self, archivo):\n",
        "\n",
        "        im = Image.open(archivo)\n",
        "        return im\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        nombre_archivo = self.imagenes[idx]\n",
        "        clase = self.imgs_to_class[idx]\n",
        "        ruta_img = join(self.root, str(clase))\n",
        "        ruta_img = join(ruta_img, nombre_archivo)\n",
        "        img = self.obtener_imagen(ruta_img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, clase\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imagenes)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahbf-pLNsW-A",
        "outputId": "6a59ff91-95a7-41ab-a458-f32b8f376165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "transforms = Compose([Resize((224,224)), ToTensor()])\n",
        "f = Flowers('flowers_dataset/train', transform=transforms)\n",
        "display(f[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(tensor([[[0.0157, 0.0078, 0.0235,  ..., 0.1961, 0.2000, 0.1647],\n",
              "          [0.0000, 0.0000, 0.0157,  ..., 0.0588, 0.0431, 0.0471],\n",
              "          [0.0157, 0.0078, 0.0353,  ..., 0.1294, 0.1137, 0.1255],\n",
              "          ...,\n",
              "          [0.2078, 0.1804, 0.1569,  ..., 0.0627, 0.0784, 0.0902],\n",
              "          [0.2157, 0.1922, 0.1059,  ..., 0.0431, 0.0706, 0.0784],\n",
              "          [0.2078, 0.1882, 0.0627,  ..., 0.0353, 0.0431, 0.0275]],\n",
              " \n",
              "         [[0.1569, 0.1412, 0.1529,  ..., 0.4588, 0.4510, 0.4196],\n",
              "          [0.1098, 0.1059, 0.1490,  ..., 0.2706, 0.2510, 0.2667],\n",
              "          [0.1216, 0.1294, 0.1804,  ..., 0.3373, 0.3098, 0.3216],\n",
              "          ...,\n",
              "          [0.2000, 0.1765, 0.1529,  ..., 0.0392, 0.0392, 0.0471],\n",
              "          [0.1882, 0.1765, 0.1059,  ..., 0.0431, 0.0549, 0.0588],\n",
              "          [0.1529, 0.1608, 0.0627,  ..., 0.0471, 0.0471, 0.0314]],\n",
              " \n",
              "         [[0.1412, 0.1255, 0.1490,  ..., 0.5843, 0.5412, 0.4941],\n",
              "          [0.1176, 0.1176, 0.1686,  ..., 0.4118, 0.3176, 0.3059],\n",
              "          [0.1608, 0.1765, 0.2431,  ..., 0.4784, 0.4824, 0.5020],\n",
              "          ...,\n",
              "          [0.6824, 0.6235, 0.5412,  ..., 0.3843, 0.4431, 0.4627],\n",
              "          [0.6431, 0.5804, 0.4471,  ..., 0.3059, 0.3529, 0.3647],\n",
              "          [0.6000, 0.5294, 0.3608,  ..., 0.2588, 0.2784, 0.2588]]]), 26)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PE9qnWDnzjX"
      },
      "source": [
        "### Iterar sobre los datos\n",
        "\n",
        "Dado un Dataset, sea hecho por nosotros o uno predefinido, iterar sobre los datos es muy sencillo. Simplemente tenemos que crear un objeto DataLoader que toma como argumento el Dataset y definir el batch size con que queremos trabajar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9BrWXFcGKKF"
      },
      "source": [
        "Este cÃ³digo iterarÃ¡ por todos los batches de ejemplos de nuestro dataset y pararÃ¡ cuando se acaben. Es decir, esto corre por una **Ã©poca**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5wPTQwiBx2W",
        "outputId": "8b1f9b0a-ab4e-4592-d4d1-284e1c9bd369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dl = DataLoader(f, batch_size=32)\n",
        "\n",
        "for n_batch, (x, target) in enumerate(train_dl):\n",
        "    print(\"\\rN_Batch: {} input: {}- Label:{}\".format(n_batch, x.shape, target.shape), end=\"\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_Batch: 177 input: torch.Size([23, 3, 224, 224])- Label:torch.Size([23])"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShVxaAFkWY8"
      },
      "source": [
        "## Loop de Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pco2wPSLBlPB"
      },
      "source": [
        "### OptimizaciÃ³n\n",
        "\n",
        "Â¿Como obtenemos los pesos Ã³ptimos para nuestra red? Si recordamos nuestras clases anteriores debemos optimizar la funciÃ³n de pÃ©rdida para tratar de encontrar los parÃ¡metros de nuestra red que minimizan su valor.\n",
        "\n",
        "Primero debemos definir la funciÃ³n de pÃ©rdida. Ã‰stas estÃ¡n definidas en torch.nn tambiÃ©n. Las usuales son:\n",
        "\n",
        "* CrossEntropyLoss: EntropÃ­a Cruzada, mide la distancia entre dos distribuciones de probabilidad. La funciÃ³n de pÃ©rdida mÃ¡s comÃºn para problemas de clasificaciÃ³n.\n",
        "* MSELoss: Error cuadrÃ¡tico medio. PÃ©rdida usual en problemas de regresiÃ³n.\n",
        "\n",
        "Hay mÃ¡s para revisar en la documentaciÃ³n de Pytorch (https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "Dado el resultado de nuestra red y el ground truth que deberÃ­amos predecir, la pÃ©rdida es:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkR0nWLUDOrD"
      },
      "source": [
        "loss = funcion_perdida(output, target) # No correr este cÃ³digo, va a dar error! Es un ejemplo!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z61_pCzKDVPb"
      },
      "source": [
        "SÃºper, tenemos la pÃ©rdida, Â¿cÃ³mo calculamos los gradientes?\n",
        "\n",
        "Para eso necesitamos un algoritmo de optimizaciÃ³n. En el curso de Herramientas verÃ¡n los algoritmos en detalle, pero les deberÃ­a sonar Stochastic Gradient Descent (SGD), que es el algoritmo estÃ¡ndar de optimizaciÃ³n. Este ya estÃ¡ implementado por el paquete torch.optim.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdfXdGgkEFXp"
      },
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "optimizer = SGD(model.parameters())     # Vinculamos el reciÃ©n creado optimizador\n",
        "                                        # a los parÃ¡metros de nuestro modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRakjFJ1Ec8u"
      },
      "source": [
        "Esto por sÃ­ solo todavÃ­a no hace nada. El optimizador va a ir gestionando los gradientes que le llegan a cada parÃ¡metro de nuestro modelo. ActualizarÃ¡ los valores de los parÃ¡metros de acuerdo al algoritmo de optimizaciÃ³n que implemente.\n",
        "\n",
        "Pero para gestionar gradientes tiene que sacarlos de alguna parte. Â¡Esto lo hace backpropagation! Por suerte es muy fÃ¡cil calcularlos en Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1SEJsy9FocF"
      },
      "source": [
        "loss.backward()                         # Â¡Backpropagation! Eso es todo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHc9IlalF1sb"
      },
      "source": [
        "Luego uniendo todas las piezas, en cada iteraciÃ³n de nuestro algoritmo de entrenamiento haremos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3CqYbbljsJC"
      },
      "source": [
        "optimizer.zero_grad()                   # 1. Hacemos cero los gradientes de los parÃ¡metros\n",
        "output = model(input)                   # 2. Propagamos los datos de entrada por nuestro modelo\n",
        "loss = funcion_perdida(output, target)  # 3. CÃ¡lculamos la pÃ©rdida\n",
        "loss.backward()                         # 4. Â¡Backpropagation! Calculamos los gradientes \n",
        "                                        # para nuestros parÃ¡metros. Â¡Los gradientes \n",
        "                                        # dejan de ser 0!\n",
        "optimizer.step()                        # 5. Actualizamos los parÃ¡metros de nuestro modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2lKeEmPkFxN"
      },
      "source": [
        "## EvaluaciÃ³n de Rendimiento\n",
        "\n",
        "Â¿CÃ³mo evaluamos el rendimiento? En problemas de clasificaciÃ³n lo que usualmente haremos es comparar el ground truth respecto a lo que predecimos. Â¿QuÃ© es lo que predecimos? Usualmente serÃ¡ la clase de mayor valor en su salida entre las N clases que tenemos que predecir. Esto lo podemos hacer usando la funciÃ³n *argmax* de Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDF-5Ei0_Kkh"
      },
      "source": [
        "output = model(input)                       # Tensor de salida de tamaÃ±o (batch_size, n_clases)\n",
        "preds = output.argmax(dim=1)                # Nos quedamos con el Ã­ndice que tiene mayor valor\n",
        "                                            # entre las N clases.\n",
        "n_correctas = (preds == targets).sum()      # preds == targets entrega un tensor de 1s o 0s.\n",
        "total = targets.shape[0]                    # Total de ejemplos\n",
        "acc = n_correctas/total                     # Accuracy es correctas/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXwwivwjAKo"
      },
      "source": [
        "## Uniendo todo\n",
        "\n",
        "Vamos a unir todos estos componentes para armar un flujo de entrenamiento completo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZOhD3d40KXu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su mÃ³dulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquÃ­ armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: ConvoluciÃ³n, Pooling y ActivaciÃ³n.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la ConvoluciÃ³n\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # TamaÃ±o de la ConvoluciÃ³n\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # CuÃ¡ntos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # ActivaciÃ³n                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # AquÃ­ armamos cÃ³mo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrÃ¡s de la\n",
        "                                 # otra. No todas las redes son asÃ­.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCdJwSCajFsr",
        "outputId": "34b3b089-2668-4d1b-df99-842d7f90c62f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 20\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la funciÃ³n de pÃ©rdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteraciÃ³n\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parÃ¡metros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parÃ¡metros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.45 Correctas: 165.0 Total: 5687.0 Accuracy: 2.90%\n",
            "Epoca 2: Loss: 4.03 Correctas: 293.0 Total: 5687.0 Accuracy: 5.15%\n",
            "Epoca 3: Loss: 4.04 Correctas: 360.0 Total: 5687.0 Accuracy: 6.33%\n",
            "Epoca 4: Loss: 3.84 Correctas: 441.0 Total: 5687.0 Accuracy: 7.75%\n",
            "Epoca 5: Loss: 3.47 Correctas: 592.0 Total: 5687.0 Accuracy: 10.41%\n",
            "Epoca 6: Loss: 3.61 Correctas: 728.0 Total: 5687.0 Accuracy: 12.80%\n",
            "Epoca 7: Loss: 3.06 Correctas: 868.0 Total: 5687.0 Accuracy: 15.26%\n",
            "Epoca 8: Loss: 2.90 Correctas: 1086.0 Total: 5687.0 Accuracy: 19.10%\n",
            "Epoca 9: Loss: 2.91 Correctas: 1300.0 Total: 5687.0 Accuracy: 22.86%\n",
            "Epoca 10: Loss: 3.01 Correctas: 1357.0 Total: 5687.0 Accuracy: 23.86%\n",
            "Epoca 11: Loss: 2.78 Correctas: 1654.0 Total: 5687.0 Accuracy: 29.08%\n",
            "Epoca 12: Loss: 2.17 Correctas: 1933.0 Total: 5687.0 Accuracy: 33.99%\n",
            "Epoca 13: Loss: 2.43 Correctas: 2225.0 Total: 5687.0 Accuracy: 39.12%\n",
            "Epoca 14: Loss: 2.18 Correctas: 2500.0 Total: 5687.0 Accuracy: 43.96%\n",
            "Epoca 15: Loss: 1.54 Correctas: 2762.0 Total: 5687.0 Accuracy: 48.57%\n",
            "Epoca 16: Loss: 1.36 Correctas: 3105.0 Total: 5687.0 Accuracy: 54.60%\n",
            "Epoca 17: Loss: 1.06 Correctas: 3422.0 Total: 5687.0 Accuracy: 60.17%\n",
            "Epoca 18: Loss: 1.07 Correctas: 3764.0 Total: 5687.0 Accuracy: 66.19%\n",
            "Epoca 19: Loss: 0.76 Correctas: 4066.0 Total: 5687.0 Accuracy: 71.50%\n",
            "Epoca 20: Loss: 0.70 Correctas: 4409.0 Total: 5687.0 Accuracy: 77.53%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmpMxT9_ypG"
      },
      "source": [
        "### Evaluando el modelo en el conjunto de Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXaeSaTV-KzJ",
        "outputId": "85d4270f-68eb-48ab-e39d-13cc3129a115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteraciÃ³n\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluaciÃ³n\n",
        "    with torch.no_grad():               # No se calcularÃ¡ informaciÃ³n de gradientes\n",
        "                                        # en el cÃ³digo de mÃ¡s abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 3.62 Correctas: 648.0 Total: 1738.0 Accuracy: 37.28%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Hrw55cmD-d"
      },
      "source": [
        "## Guardar el Modelo\n",
        "\n",
        "Una vez entrenado, querremos guardar el modelo para no tener que reentrenarlo cada vez que lo queramos usar. Esto es fÃ¡cil de hacer en Pytorch. Hay dos formas de hacerlo:\n",
        "\n",
        "* La forma bruta es guardar el objeto completo usando torch.save. Esto guarda todo el objeto a disco. Por lo tanto ocupa mÃ¡s espacio. Pero este no es el mayor problema, sino que el modelo queda vinculado al computador en que se creÃ³. Algo nada apetecible si queremos correr el modelo entrenado en otra mÃ¡quina. Si se desea proseguir, se hace de la siguiente manera:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTj1Wvg_mYlI"
      },
      "source": [
        "torch.save(model, \"modelo_entrenado.pth\")\n",
        "\n",
        "modelo = torch.load(\"modelo_entrenado.pth\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjKpS6ndmd2d"
      },
      "source": [
        "* La forma mÃ¡s eficiente y correcta es simplemente guardar los pesos. Estos se encuentran en una estructura llamada *'state_dict'* en el modelo. Una vez guardados, para recuperar nuestro modelo, tenemos que crear un modelo nuevo y ocupar el mÃ©todo *'load_state_dict'* para cargar los pesos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2NceHcCmd_E",
        "outputId": "3a637f44-b959-4af3-aa35-d58b92cd216b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.save(model.state_dict(), \"pesos_modelo_entrenado.pth\") # Guardamos a disco los pesos\n",
        "\n",
        "modelo = MiAlexNet()                                # Modelo con pesos aleatorios\n",
        "pesos = torch.load(\"pesos_modelo_entrenado.pth\") # Cargamos los pesos a una variable\n",
        "modelo.load_state_dict(pesos)                       # Â¡Los pesos se encuentran \n",
        "                                                    # cargados en el modelo!"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgIRqm5YaL6"
      },
      "source": [
        "## Actividades\n",
        "\n",
        "1. Entrene el modelo MiAlexNet por 10 Ã©pocas. Â¿QuÃ© resultados obtiene en train y test?\n",
        "2. Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. EntrÃ©nelo por 10 Ã©pocas. Â¿Ve cambios en el rendimiento del modelo?\n",
        "3. Agregue capas de Batch Normalization (*BatchNorm2d*) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 Ã©pocas. Â¿Ve algÃºn cambio en el entrenamiento?\n",
        "4. Ocupe el modelo preentrenado en ImageNet de AlexNet. EntrÃ©nelo por 10 Ã©pocas. Â¿Afecta en algo en rendimiento? Para ocupar el modelo preentrenado reemplace esta lÃ­nea del cÃ³digo de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPXbZ7F6rpYH"
      },
      "source": [
        "model = MiAlexNet()     # Creamos el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJPwrpZOrpfL"
      },
      "source": [
        "Por esta otra lÃ­nea:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjA6rheBq3YC"
      },
      "source": [
        "from torchvision.models import alexnet\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "model.features.requires_grad_(False)\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 102),\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Q3BQkaer6E"
      },
      "source": [
        "### Respuestas Actividad\n",
        "\n",
        "Por favor, sus respuestas a la actividad acÃ¡. No modificar el cÃ³digo anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APuyXZZteWZw"
      },
      "source": [
        "**Actividad 1**\n",
        "\n",
        "Entrene el modelo MiAlexNet por 10 Ã©pocas. Â¿QuÃ© resultados obtiene en train y test?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9OnSDXeeWhF",
        "outputId": "d78225ff-3113-49fa-c559-665742b38522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la funciÃ³n de pÃ©rdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteraciÃ³n\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parÃ¡metros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parÃ¡metros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.51 Correctas: 147.0 Total: 5687.0 Accuracy: 2.58%\n",
            "Epoca 2: Loss: 4.38 Correctas: 218.0 Total: 5687.0 Accuracy: 3.83%\n",
            "Epoca 3: Loss: 3.98 Correctas: 342.0 Total: 5687.0 Accuracy: 6.01%\n",
            "Epoca 4: Loss: 3.81 Correctas: 455.0 Total: 5687.0 Accuracy: 8.00%\n",
            "Epoca 5: Loss: 3.33 Correctas: 606.0 Total: 5687.0 Accuracy: 10.66%\n",
            "Epoca 6: Loss: 3.51 Correctas: 756.0 Total: 5687.0 Accuracy: 13.29%\n",
            "Epoca 7: Loss: 3.16 Correctas: 895.0 Total: 5687.0 Accuracy: 15.74%\n",
            "Epoca 8: Loss: 3.00 Correctas: 992.0 Total: 5687.0 Accuracy: 17.44%\n",
            "Epoca 9: Loss: 2.87 Correctas: 1251.0 Total: 5687.0 Accuracy: 22.00%\n",
            "Epoca 10: Loss: 2.75 Correctas: 1378.0 Total: 5687.0 Accuracy: 24.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i19YL0VNq7qW",
        "outputId": "307d4f73-c9b2-4a86-c1c0-777b26d5a4ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteraciÃ³n\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluaciÃ³n\n",
        "    with torch.no_grad():               # No se calcularÃ¡ informaciÃ³n de gradientes\n",
        "                                        # en el cÃ³digo de mÃ¡s abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.89 Correctas: 374.0 Total: 1738.0 Accuracy: 21.52%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUreTdqo3awe"
      },
      "source": [
        "Al reducir epochs de 20 a 10, el accuracy del test set baja de 37% a 22%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh3US3SM3aT0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVzxMB2JeWpn"
      },
      "source": [
        "**Actividad 2**\n",
        "\n",
        "Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. EntrÃ©nelo por 10 Ã©pocas. Â¿Ve cambios en el rendimiento del modelo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srgh6pxteWvE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su mÃ³dulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquÃ­ armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: ConvoluciÃ³n, Pooling y ActivaciÃ³n.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la ConvoluciÃ³n\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # TamaÃ±o de la ConvoluciÃ³n\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # CuÃ¡ntos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # ActivaciÃ³n                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fcDropout = nn.Sequential( nn.Dropout() )\n",
        "        \n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # AquÃ­ armamos cÃ³mo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrÃ¡s de la\n",
        "                                 # otra. No todas las redes son asÃ­.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fcDropout(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHOsgZFVp6CV",
        "outputId": "e3e56500-55b2-422b-9133-98aa804dd26b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la funciÃ³n de pÃ©rdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteraciÃ³n\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parÃ¡metros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parÃ¡metros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.43 Correctas: 157.0 Total: 5687.0 Accuracy: 2.76%\n",
            "Epoca 2: Loss: 4.51 Correctas: 175.0 Total: 5687.0 Accuracy: 3.08%\n",
            "Epoca 3: Loss: 4.44 Correctas: 189.0 Total: 5687.0 Accuracy: 3.32%\n",
            "Epoca 4: Loss: 4.19 Correctas: 343.0 Total: 5687.0 Accuracy: 6.03%\n",
            "Epoca 5: Loss: 4.18 Correctas: 484.0 Total: 5687.0 Accuracy: 8.51%\n",
            "Epoca 6: Loss: 3.36 Correctas: 633.0 Total: 5687.0 Accuracy: 11.13%\n",
            "Epoca 7: Loss: 3.15 Correctas: 733.0 Total: 5687.0 Accuracy: 12.89%\n",
            "Epoca 8: Loss: 3.37 Correctas: 846.0 Total: 5687.0 Accuracy: 14.88%\n",
            "Epoca 9: Loss: 3.17 Correctas: 938.0 Total: 5687.0 Accuracy: 16.49%\n",
            "Epoca 10: Loss: 2.98 Correctas: 1095.0 Total: 5687.0 Accuracy: 19.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMmbpahrSZM",
        "outputId": "d08d82d2-7d35-4021-9c0c-662e8cc6e3a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteraciÃ³n\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluaciÃ³n\n",
        "    with torch.no_grad():               # No se calcularÃ¡ informaciÃ³n de gradientes\n",
        "                                        # en el cÃ³digo de mÃ¡s abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 3.19 Correctas: 313.0 Total: 1738.0 Accuracy: 18.01%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPr29eGV3-kr"
      },
      "source": [
        "El accuracy del training y testing son muy similares (~18%), indicando que no hay problemas de overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDIv-92OeW7W"
      },
      "source": [
        "**Actividad 3**\n",
        "\n",
        "Agregue capas de Batch Normalization (BatchNorm2d) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 Ã©pocas. Â¿Ve algÃºn cambio en el entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz27SKTHeXCq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su mÃ³dulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquÃ­ armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: ConvoluciÃ³n, Pooling y ActivaciÃ³n.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la ConvoluciÃ³n\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # TamaÃ±o de la ConvoluciÃ³n\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # CuÃ¡ntos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # ActivaciÃ³n                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "\n",
        "        self.bn2 = nn.Sequential( BatchNorm2d(256, momentum = None, eps=0.0)  )                           \n",
        "\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "\n",
        "        self.bn3 = nn.Sequential( BatchNorm2d(384, momentum = None, eps=0.0)  )                           \n",
        "\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "\n",
        "        self.bn4 = nn.Sequential( BatchNorm2d(384, momentum = None, eps=0.0)  )                           \n",
        "\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096        \n",
        "        \n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # AquÃ­ armamos cÃ³mo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrÃ¡s de la\n",
        "                                 # otra. No todas las redes son asÃ­.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdrsNw3PtC8g",
        "outputId": "e530c5e0-c727-4e9b-b720-a46a30151640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la funciÃ³n de pÃ©rdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteraciÃ³n\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parÃ¡metros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parÃ¡metros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.52 Correctas: 159.0 Total: 5687.0 Accuracy: 2.80%\n",
            "Epoca 2: Loss: 4.55 Correctas: 166.0 Total: 5687.0 Accuracy: 2.92%\n",
            "Epoca 3: Loss: 4.41 Correctas: 168.0 Total: 5687.0 Accuracy: 2.95%\n",
            "Epoca 4: Loss: 4.61 Correctas: 173.0 Total: 5687.0 Accuracy: 3.04%\n",
            "Epoca 5: Loss: 4.55 Correctas: 169.0 Total: 5687.0 Accuracy: 2.97%\n",
            "Epoca 6: Loss: 4.52 Correctas: 172.0 Total: 5687.0 Accuracy: 3.02%\n",
            "Epoca 7: Loss: 4.43 Correctas: 180.0 Total: 5687.0 Accuracy: 3.17%\n",
            "Epoca 8: Loss: 4.56 Correctas: 172.0 Total: 5687.0 Accuracy: 3.02%\n",
            "Epoca 9: Loss: 4.58 Correctas: 180.0 Total: 5687.0 Accuracy: 3.17%\n",
            "Epoca 10: Loss: 4.55 Correctas: 166.0 Total: 5687.0 Accuracy: 2.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1OLBnybtFZK",
        "outputId": "72fa4eb9-238f-45fe-f120-a68a27d49933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteraciÃ³n\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluaciÃ³n\n",
        "    with torch.no_grad():               # No se calcularÃ¡ informaciÃ³n de gradientes\n",
        "                                        # en el cÃ³digo de mÃ¡s abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 4.51 Correctas: 53.0 Total: 1738.0 Accuracy: 3.05%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL20N-G14HFh"
      },
      "source": [
        "El accuracy es muy bajo (3%), indicando que para el mismo numero de epochs, batch normalization da peores resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3esj4ZFEeX3w"
      },
      "source": [
        "**Actividad 4**\n",
        "\n",
        "Ocupe el modelo preentrenado en ImageNet de AlexNet. EntrÃ©nelo por 10 Ã©pocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMb0lgVdeX9R",
        "outputId": "70eb3881-c6aa-450c-ee71-cc4d9c75fc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "29c7d49265ab46729d36817384d51ce2",
            "1bbed9c126cf4251b749313941252afd",
            "75e4e0a4470041d2ba76534e2f4892fc",
            "e0a5bbcf2a0f4afda22121429ef9a527",
            "2634b54a3c1b4f499ab08a36e68c6c03",
            "4f9dc304981c433b9c4434f30d5bf5b7",
            "411c298ba5724bdb894981f258a2b2c0",
            "1d2048bad8ff43b58b3e2974ba6ada36"
          ]
        }
      },
      "source": [
        "\n",
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "model.features.requires_grad_(False)\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 102),\n",
        "        )\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la funciÃ³n de pÃ©rdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteraciÃ³n\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parÃ¡metros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parÃ¡metros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29c7d49265ab46729d36817384d51ce2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoca 1: Loss: 2.38 Correctas: 1139.0 Total: 5687.0 Accuracy: 20.03%\n",
            "Epoca 2: Loss: 1.61 Correctas: 2840.0 Total: 5687.0 Accuracy: 49.94%\n",
            "Epoca 3: Loss: 1.54 Correctas: 3503.0 Total: 5687.0 Accuracy: 61.60%\n",
            "Epoca 4: Loss: 1.02 Correctas: 3905.0 Total: 5687.0 Accuracy: 68.67%\n",
            "Epoca 5: Loss: 0.79 Correctas: 4103.0 Total: 5687.0 Accuracy: 72.15%\n",
            "Epoca 6: Loss: 0.75 Correctas: 4345.0 Total: 5687.0 Accuracy: 76.40%\n",
            "Epoca 7: Loss: 0.38 Correctas: 4441.0 Total: 5687.0 Accuracy: 78.09%\n",
            "Epoca 8: Loss: 0.53 Correctas: 4478.0 Total: 5687.0 Accuracy: 78.74%\n",
            "Epoca 9: Loss: 0.79 Correctas: 4658.0 Total: 5687.0 Accuracy: 81.91%\n",
            "Epoca 10: Loss: 0.98 Correctas: 4636.0 Total: 5687.0 Accuracy: 81.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvr0XBBZyn6_",
        "outputId": "7de14df8-cbb1-4cab-bfce-dc79412ef2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteraciÃ³n\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluaciÃ³n\n",
        "    with torch.no_grad():               # No se calcularÃ¡ informaciÃ³n de gradientes\n",
        "                                        # en el cÃ³digo de mÃ¡s abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pÃ©rdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El mÃ¡ximo valor es nuestra predicciÃ³n\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la Ã©poca\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaÃ±o del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.78 Correctas: 1354.0 Total: 1738.0 Accuracy: 77.91%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7va6b8y4Yv1"
      },
      "source": [
        "Al continuar entrenando el modelo original, aumenta el accuracy a un 82% en training, y 78% en testing. Esto indica que no hay problemas de overfitting, y en realidad era suficiente entrenar por mÃ¡s epochs en vez de aplicar dropout o overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_UFnyuJ4TmX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio_2_Redes_Convolucionales_Diplomado_IA_FranciscoMena.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7b42ef04c0047f98e61e28d3bac7d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_611c8dd6f5f84609b53b2de26bb14c2c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_563a4017edda47b9ad295d26c33cdba5",
              "IPY_MODEL_fd8fa0127a5e4a5aa4b9ec901c62b6d2"
            ]
          }
        },
        "611c8dd6f5f84609b53b2de26bb14c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "563a4017edda47b9ad295d26c33cdba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_91185e0678894f919416ddb1af037d61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3180775a09e4bf09e9ccf4bf2588100"
          }
        },
        "fd8fa0127a5e4a5aa4b9ec901c62b6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41c5b240be864c60802aca248ea00614",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1057602.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_385f2a0078684bfaa158c64577fa2847"
          }
        },
        "91185e0678894f919416ddb1af037d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3180775a09e4bf09e9ccf4bf2588100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41c5b240be864c60802aca248ea00614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "385f2a0078684bfaa158c64577fa2847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98725b795e6a4313a213ed6d94df963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb26f330e0384a68a4402a848af3778a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e65a1cfdbb54111b4b6a2c7b0536d7b",
              "IPY_MODEL_0ffb3b339239455cad0761af02cc2543"
            ]
          }
        },
        "fb26f330e0384a68a4402a848af3778a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e65a1cfdbb54111b4b6a2c7b0536d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_831f3b33dd1d4dae8c512d0c0b7714fa",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd96c935ef7c4896a56de3f5c4d9f1b8"
          }
        },
        "0ffb3b339239455cad0761af02cc2543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8cdbf6332ba470e8cc311a164372691",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5572bcca31c2431485a061648be497cc"
          }
        },
        "831f3b33dd1d4dae8c512d0c0b7714fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd96c935ef7c4896a56de3f5c4d9f1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8cdbf6332ba470e8cc311a164372691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5572bcca31c2431485a061648be497cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "174ca99f02f243b5937fc15c6bd5aa69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e26376e6475c417ab0040e5a04d90e7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20b5a356d7174842b6363876a57b7915",
              "IPY_MODEL_7fb7694f9f29451e8d1421031c76963f"
            ]
          }
        },
        "e26376e6475c417ab0040e5a04d90e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20b5a356d7174842b6363876a57b7915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9e7fadf908c465aaf3edd81a1e5ceaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd8273bb77fd4ec383d20a95125a692a"
          }
        },
        "7fb7694f9f29451e8d1421031c76963f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75c3e3f1458f4fbf909024c2d7746f28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:01&lt;00:00, 1530466.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82d9ed73bef94b878172d2838edac6bd"
          }
        },
        "b9e7fadf908c465aaf3edd81a1e5ceaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd8273bb77fd4ec383d20a95125a692a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75c3e3f1458f4fbf909024c2d7746f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82d9ed73bef94b878172d2838edac6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a57d64a6cd8544d89a8434d998a6fa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1f172893ae64bf2b96e784565f50785",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4785dbb7936d474a85726c42d0a00db0",
              "IPY_MODEL_82951eb7fd08459c8d27628df73e331a"
            ]
          }
        },
        "a1f172893ae64bf2b96e784565f50785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4785dbb7936d474a85726c42d0a00db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0d6463239624d2ea0136142b5d8573c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6521283e806249c496a5a366cecc5282"
          }
        },
        "82951eb7fd08459c8d27628df73e331a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8a7a456d8164cf4b7a4e76fe5cee8d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 21219.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f7372ac218f41d986cc06e056b99dc2"
          }
        },
        "b0d6463239624d2ea0136142b5d8573c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6521283e806249c496a5a366cecc5282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8a7a456d8164cf4b7a4e76fe5cee8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f7372ac218f41d986cc06e056b99dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a93a1220aa643d2bf0493cea706733f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0f2f1f22eb149f39c2b6711053ea489",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4b9d812925348758736e8e23708e61b",
              "IPY_MODEL_e724ad7d3639474fb60c5f248da57ada"
            ]
          }
        },
        "a0f2f1f22eb149f39c2b6711053ea489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4b9d812925348758736e8e23708e61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfc9079cfd484d6c84451e9f79d67915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c4df75ab97747d7ac6e0ed64e110648"
          }
        },
        "e724ad7d3639474fb60c5f248da57ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3daf2adaff44c3dac904b66c7381ef3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:17&lt;00:00, 38641693.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78c4b6acd6d44f08a0725b867bbc599b"
          }
        },
        "bfc9079cfd484d6c84451e9f79d67915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c4df75ab97747d7ac6e0ed64e110648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3daf2adaff44c3dac904b66c7381ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78c4b6acd6d44f08a0725b867bbc599b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29c7d49265ab46729d36817384d51ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bbed9c126cf4251b749313941252afd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75e4e0a4470041d2ba76534e2f4892fc",
              "IPY_MODEL_e0a5bbcf2a0f4afda22121429ef9a527"
            ]
          }
        },
        "1bbed9c126cf4251b749313941252afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75e4e0a4470041d2ba76534e2f4892fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2634b54a3c1b4f499ab08a36e68c6c03",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f9dc304981c433b9c4434f30d5bf5b7"
          }
        },
        "e0a5bbcf2a0f4afda22121429ef9a527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_411c298ba5724bdb894981f258a2b2c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [23:43&lt;00:00, 172kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d2048bad8ff43b58b3e2974ba6ada36"
          }
        },
        "2634b54a3c1b4f499ab08a36e68c6c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f9dc304981c433b9c4434f30d5bf5b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "411c298ba5724bdb894981f258a2b2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d2048bad8ff43b58b3e2974ba6ada36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzO98wJgjmOd"
      },
      "source": [
        "# Laboratorio 2 - Redes Convolucionales - Diplomado Inteligencia Artificial UC\n",
        "\n",
        "**IMPORTANTE: habrá un bonus de 1 décima para todos aquellos alumnos/as que muestren buen orden en sus respuestas (esto aplica a legibilidad de código, buena redacción, formalidad, organización del jupyter notebook, seguimiento de instrucciones, etc). El criterio lo pondrá cada ayudante corrector. La nota máxima obtenible en el laboratorio es 7.0.**\n",
        "\n",
        "En este laboratorio nos interiorizaremos en cómo funciona Pytorch (https://pytorch.org/), el framework de Facebook para implementar Redes Neuronales Profundas.\n",
        "\n",
        "Vamos a ver varias partes distintas del flujo de entrenamiento, desde cómo cargamos los datos, cómo creamos redes, cómo las entrenamos y cómo validamos su rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og-s3Wv2oEOe"
      },
      "source": [
        "## El Tensor: la unidad fundamental.\n",
        "\n",
        "Los tensores son el elemento fundamental con que trabajarán nuestras redes profundas. Un tensor es simplemente una matriz de n-dimensiones. \n",
        "\n",
        "* En **imágenes**, usamos tensores de 4 dimensiones: 3 dimensiones (alto, ancho y color) más una cuarta dimensión asociada a los elementos del batch.\n",
        "\n",
        "* Cuando trabajamos con **texto** podemos tener tensores en 3 dimensiones (dimensión de embedding, palabras y batch).\n",
        "\n",
        "* Si trabajamos con **videos** tenemos que agregar otra dimensión para el tiempo. En fin, todos estos datos distintos al final se representan como matrices de números en 3, 4 ó 5 dimensiones distintas.\n",
        "\n",
        "Pytorch representa los tensores via la clase torch.Tensor. Todas las redes neuronales que hagamos requieren tensores para poder trabajar. Nuestros datasets no servirán de nada si no podemos transformarlos en tensores que podamos ocupar con nuestras redes. Si han trabajado con *ndarray* de Numpy la forma de ocuparlos es muy similar. Veamos un tensor de ejemplo de 3 dimensiones: ancho, alto y batch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5omMrW5bUS",
        "outputId": "2ac7c846-849e-4604-f589-3b452fd92405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "batch_dim = 5\n",
        "alto = 2\n",
        "ancho = 3\n",
        "tensor_ejemplo = torch.randn((batch_dim, ancho, alto)).float() # Tensor aleatorio\n",
        "print(\"El tensor es: {}\\n\".format(tensor_ejemplo))\n",
        "print(\"La forma del tensor es: {}\".format(tensor_ejemplo.shape))\n",
        "print(\"El tipo del tensor es: {}\".format(type(tensor_ejemplo)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El tensor es: tensor([[[ 0.0628, -0.9507],\n",
            "         [-1.2270,  0.4503],\n",
            "         [ 0.3438,  1.0220]],\n",
            "\n",
            "        [[-0.0261,  0.6921],\n",
            "         [ 0.0907,  0.8105],\n",
            "         [ 0.6341, -1.4089]],\n",
            "\n",
            "        [[ 0.2022,  0.9402],\n",
            "         [-2.2096,  1.0981],\n",
            "         [ 1.0203, -0.7037]],\n",
            "\n",
            "        [[-0.1311,  0.8031],\n",
            "         [-0.6545, -0.3806],\n",
            "         [-0.9115, -0.3599]],\n",
            "\n",
            "        [[ 0.4298,  0.6213],\n",
            "         [-0.4998,  1.6038],\n",
            "         [-1.3326,  1.4618]]])\n",
            "\n",
            "La forma del tensor es: torch.Size([5, 3, 2])\n",
            "El tipo del tensor es: <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHpZ99Rvjgte"
      },
      "source": [
        "Crear un tensor desde un arreglo de Python es sencillo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn84KtqwjObX",
        "outputId": "f35487ab-a15f-4a82-d5c1-1e23c7cd458f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arreglo = [[1, 2, 3], [4, 5, 6]]\n",
        "tensor_desde_arreglo = torch.tensor(arreglo)\n",
        "print(tensor_desde_arreglo, tensor_desde_arreglo.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]]) torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwE7bG-56rx6"
      },
      "source": [
        "Uno trabaja los tensores de la misma manera que cualquier otra variable numérica en Python. Se pueden, sumar y restar sin problema. La multiplicación por escalares no supone problema y la multiplicación de tensores también está soportada.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH-U3PPi7az0",
        "outputId": "bd5c28b0-f3a0-4a4d-c91b-49b1a98db545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor_1 = torch.randn((1,2,3))\n",
        "tensor_2 = torch.randn((1,2,3))\n",
        "\n",
        "tensor_3 = tensor_1 + tensor_2\n",
        "\n",
        "print(tensor_1)\n",
        "print(tensor_2)\n",
        "print(tensor_3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.4805, -1.0274, -0.4928],\n",
            "         [-0.2328, -0.5994, -0.4366]]])\n",
            "tensor([[[-0.3093,  0.3467,  1.8701],\n",
            "         [-0.1841, -0.7706, -0.3375]]])\n",
            "tensor([[[ 0.1712, -0.6807,  1.3773],\n",
            "         [-0.4169, -1.3700, -0.7742]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoNoKKFATdEv"
      },
      "source": [
        "Podemos indexarlos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OUPry8-TcGX",
        "outputId": "e5526084-348b-4850-94cd-7905e766456c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor_indexado = tensor_1[:,:,:2]\n",
        "print(tensor_indexado, tensor_indexado.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.4805, -1.0274],\n",
            "         [-0.2328, -0.5994]]]) torch.Size([1, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGAdf1Zz7a8T"
      },
      "source": [
        "#### Sobre la dimensión batch\n",
        "\n",
        "La dimensión de batch es importante pues es la que nos permite poder entrenar de forma paralela en nuestras GPUs. El estándar de Pytorch es que ésta es la primera dimensión de nuestros tensores siempre. Aunque solo evaluar un elemento en nuestra red, este debe tener una dimensión de batch en su primer lugar o sino no funcionará. También es necesario mencionar que Pytorch espera siempre que la dimensión del canal vaya antes que las dimensiones de ancho y alto en imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX3ER77PS_H_"
      },
      "source": [
        "### Sobre el dispositivo asociado\n",
        "\n",
        "Los tensores son procesados por la CPU o por una GPU. Como quizás hemos escuchado antes, sabemos que parte de la explosión de Deep Learning viene por la disponibilidad de GPUs cada vez más poderosas. Para poder trabajar en GPU un tensor tenemos que hacer lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ln8Wq3wURfu"
      },
      "source": [
        "tensor_nuevo = torch.randn((1,2,3))     # Por defecto el tensor está en CPU\n",
        "tensor_nuevo_gpu = tensor_nuevo.cuda()  # Creé una copia de tensor_nuevo en GPU!\n",
        "otra_forma = tensor_nuevo.to('cuda')    # Creé otra copia de tensor_nuevo en GPU!"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JmfrUSLkF2o"
      },
      "source": [
        "## Definición del Modelo\n",
        "Como vimos en el laboratorio pasado, definir un modelo de aprendizaje profundo consiste en definir una nueva clase que herede de torch.nn.Module.\n",
        "\n",
        "Esta clase debe implementar dos métodos para funcionar como un modelo válido en Pytorch:\n",
        "\n",
        "* Método \\_\\_init\\_\\_(self): el constructor de la clase. Aquí es donde usualmente definiremos todos los elementos arquitéctonicos de nuestra red. Aquí definiremos que capas tendrá, qué funciones de activación, funciones de pooling, etc.\n",
        "\n",
        "* Método forward(self, input): define las conexiones entre capas del modelo, o cómo debe fluir la información que entra en él. Debe retornar un tensor.\n",
        "\n",
        "### Elementos arquitectónicos\n",
        "\n",
        "Todos estos elementos están definidos en el paquete torch.nn (de Neural Networks). Todos derivan de la clase torch.nn.Module.\n",
        "\n",
        "* **Linear:** capa lineal. Toma como parámetros las cantidades de neuronas de entrada y de salida.\n",
        "* **Conv1d, Conv2d, Conv3d**: capas convolucionales de 1, 2 y 3 dimensiones respectivamente. Definidas por el tamaño del kernel que ocupan, el *stride*, filtros de entrada y de salida.\n",
        "* **ReLU**: función de activación. No tiene parámetros.\n",
        "* **Sigmoid**: función de activación. No tiene parámetros.\n",
        "* **Softmax**: capa que transforma el output en una distribución de probabilidad. Parámetro es sobre la o las dimensiones que se aplica.\n",
        "* **MaxPool1d, MaxPool2d, MaxPool3d**: Funciones de pooling en 1,2 y 3 dimensiones respectivamente.\n",
        "* **Dropout**: capa que deja en 0 neuronas con probabilidad $p$. Parámetro: $p$.\n",
        "* **BatchNorm2d**: capa que normaliza el input de acuerdo a una media y varianza aprendidas. \n",
        "* **Sequential**: es un agrupador de Módulos. Se encarga de que la información fluya de forma secuencial entre los módulos que contiene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6fz8KLbXfXJ",
        "outputId": "b517f29f-ee82-43bb-bf55-c467fad59998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU, Sigmoid, Sequential, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
        "\n",
        "tensor_prueba = torch.randn((3, 5))\n",
        "\n",
        "print(tensor_prueba, tensor_prueba.shape)\n",
        "\n",
        "# Capa Lineal que va de 5 dimensiones a 8\n",
        "capa_lineal = Linear(5, 8)\n",
        "tensor_nuevo = capa_lineal(tensor_prueba)\n",
        "print(\"Tensor después de Capa Lineal:\")\n",
        "print(tensor_nuevo, tensor_nuevo.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]]) torch.Size([3, 5])\n",
            "Tensor después de Capa Lineal:\n",
            "tensor([[-1.4172,  0.2860, -0.4144,  0.4446, -1.1229, -0.3033,  0.2553, -0.2322],\n",
            "        [-0.6428,  0.0117, -0.0732,  0.5970,  0.4639, -0.0060, -0.2565, -0.4994],\n",
            "        [-0.6700,  0.3882, -0.2621,  0.1579, -1.1278, -0.8477,  0.7021,  0.3488]],\n",
            "       grad_fn=<AddmmBackward>) torch.Size([3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6q_9qzcFiP",
        "outputId": "8a1c58a4-7455-45db-d2f9-d27b15d1aa8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Funciones de Activación\n",
        "# ReLU\n",
        "relu = ReLU()\n",
        "print(\"Antes de ReLU: \")\n",
        "print(tensor_prueba)\n",
        "print(\"Después de ReLU: \")\n",
        "print(relu(tensor_prueba))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de ReLU: \n",
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]])\n",
            "Después de ReLU: \n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.2673, 0.0000],\n",
            "        [0.5121, 0.0000, 0.0000, 0.0000, 0.7996],\n",
            "        [0.0000, 0.0000, 1.5817, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL3sBxCbcLty",
        "outputId": "31b58fb8-85ff-45ed-9894-fc262e8ea2b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sigmoid\n",
        "s = Sigmoid()\n",
        "print(\"Antes de Sigmoid: \")\n",
        "print(tensor_prueba)\n",
        "print(\"Después de Sigmoid: \")\n",
        "print(s(tensor_prueba))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de Sigmoid: \n",
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]])\n",
            "Después de Sigmoid: \n",
            "tensor([[0.2156, 0.1622, 0.4712, 0.5664, 0.3955],\n",
            "        [0.6253, 0.2966, 0.2280, 0.4049, 0.6899],\n",
            "        [0.2885, 0.3764, 0.8294, 0.4894, 0.4474]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pRxMMlacFpR",
        "outputId": "ce60b294-672e-4fa6-c99b-1d4a6144fe13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Softmax\n",
        "soft = Softmax(dim=1)\n",
        "print(\"Antes de Softmax: \")\n",
        "print(tensor_prueba)\n",
        "print(\"Después de Softmax: \")\n",
        "soft_tensor = soft(tensor_prueba)\n",
        "print(soft_tensor)\n",
        "print(soft_tensor.sum(dim=1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de Softmax: \n",
            "tensor([[-1.2913, -1.6422, -0.1152,  0.2673, -0.4242],\n",
            "        [ 0.5121, -0.8636, -1.2194, -0.3850,  0.7996],\n",
            "        [-0.9025, -0.5047,  1.5817, -0.0426, -0.2112]])\n",
            "Después de Softmax: \n",
            "tensor([[0.0828, 0.0583, 0.2684, 0.3934, 0.1970],\n",
            "        [0.3154, 0.0797, 0.0558, 0.1286, 0.4205],\n",
            "        [0.0531, 0.0790, 0.6365, 0.1254, 0.1060]])\n",
            "tensor([1.0000, 1.0000, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCDkA0IFcFwG",
        "outputId": "3a746e8d-3a07-4c22-af2c-663685e9527c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sequential\n",
        "# Unamos pasos\n",
        "seq = Sequential(capa_lineal, relu, soft)\n",
        "tensor_final = seq(tensor_prueba)\n",
        "print(\"Aplicando Sequential: \")\n",
        "print(tensor_final, tensor_final.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aplicando Sequential: \n",
            "tensor([[0.1089, 0.1450, 0.1089, 0.1699, 0.1089, 0.1089, 0.1406, 0.1089],\n",
            "        [0.1062, 0.1074, 0.1062, 0.1929, 0.1688, 0.1062, 0.1062, 0.1062],\n",
            "        [0.0992, 0.1463, 0.0992, 0.1162, 0.0992, 0.0992, 0.2002, 0.1406]],\n",
            "       grad_fn=<SoftmaxBackward>) torch.Size([3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kImxDES0Zek6",
        "outputId": "99d77dd0-569e-48a4-9105-7c47224df1f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Dropout\n",
        "drop = Dropout(p=0.15) # con probabilidad de dejar en 0 de 0.15.\n",
        "tensor_dropout = drop(tensor_prueba)\n",
        "print(tensor_dropout)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.5192, -1.9319, -0.1355,  0.3144, -0.0000],\n",
            "        [ 0.0000, -1.0160, -1.4346, -0.0000,  0.9407],\n",
            "        [-1.0618, -0.5938,  1.8608, -0.0501, -0.2485]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSpvnCsuZwQo",
        "outputId": "bf01e07e-79d8-4d47-ef7a-516bca423f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batch Normalization 1d\n",
        "tensor_lineal = 20*torch.randn((3, 5))  # Una imagen con varianza alta\n",
        "bn = BatchNorm1d(5, momentum=None)                             # 3 es el número de canales\n",
        "\n",
        "\n",
        "print(\"La media de los vectores originales por dimensión es: {}\".format(tensor_lineal.mean(dim=[0])))   \n",
        "print(\"La varianza de los vectores originales por dimensión es: {}\".format(tensor_lineal.var(dim=[0], unbiased=False)))\n",
        "print(\"Las medias por dimensión de BN inicialmente son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por dimensión de BN inicialmente son: {}\".format(bn.running_var))\n",
        "\n",
        "tensor_bn = bn(tensor_lineal)\n",
        "\n",
        "print(\"La media por dimensión del resultado es: {}\".format(tensor_bn.mean(dim=[0])))   \n",
        "print(\"La varianza por dimensión del resultado es: {}\".format(tensor_bn.var(dim=[0], unbiased=False)))\n",
        "print(\"Las medias por dimensión de BN ahora son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por dimensión de BN ahora son: {}\".format(bn.running_var))  \n",
        "\n",
        "for n, p in bn.named_parameters():\n",
        "    print(n,p)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de los vectores originales por dimensión es: tensor([ 7.0683,  8.7154,  8.1161, 22.8584, -4.9177])\n",
            "La varianza de los vectores originales por dimensión es: tensor([436.5844, 427.5392, 706.6785, 271.8681, 539.7061])\n",
            "Las medias por dimensión de BN inicialmente son: tensor([0., 0., 0., 0., 0.])\n",
            "Las varianzas por dimensión de BN inicialmente son: tensor([1., 1., 1., 1., 1.])\n",
            "La media por dimensión del resultado es: tensor([-9.9341e-09,  0.0000e+00,  0.0000e+00, -3.9736e-08,  0.0000e+00],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "La varianza por dimensión del resultado es: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<VarBackward1>)\n",
            "Las medias por dimensión de BN ahora son: tensor([ 7.0683,  8.7154,  8.1161, 22.8584, -4.9177])\n",
            "Las varianzas por dimensión de BN ahora son: tensor([ 654.8766,  641.3088, 1060.0178,  407.8022,  809.5591])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTjNvAWfocwY",
        "outputId": "43397bb2-0b90-4968-b27d-9868d29b6805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batch Normalization 2d\n",
        "tensor_imagenes = 20*torch.randn((3, 3, 2, 2))  # Una imagen con varianza alta\n",
        "bn = BatchNorm2d(3, momentum = None, eps=0.0)                             # 3 es el número de canales\n",
        "\n",
        "\n",
        "print(\"La media de las imágenes originales por canal es: {}\".format(tensor_imagenes.mean(dim=[0,2,3])))   \n",
        "print(\"La varianza de las imágenes originales por canal es: {}\".format(tensor_imagenes.var(dim=[0,2,3], unbiased=False)))\n",
        "print(\"Las medias por canal de BN inicialmente son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por canal de BN inicialmente son: {}\".format(bn.running_var))\n",
        "\n",
        "tensor_bn = bn(tensor_imagenes)\n",
        "\n",
        "print(\"La media por canal es: {}\".format(tensor_bn.mean(dim=[0,2,3])))   \n",
        "print(\"La varianza por canal es: {}\".format(tensor_bn.var(dim=[0,2,3], unbiased=False)))\n",
        "print(\"Las medias por canal de BN ahora son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por canal de BN ahora son: {}\".format(bn.running_var))\n",
        "\n",
        "for n, p in bn.named_parameters():\n",
        "    print(n,p)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de las imágenes originales por canal es: tensor([ 7.9804,  2.7427, -1.3530])\n",
            "La varianza de las imágenes originales por canal es: tensor([446.7048, 501.9675, 587.4157])\n",
            "Las medias por canal de BN inicialmente son: tensor([0., 0., 0.])\n",
            "Las varianzas por canal de BN inicialmente son: tensor([1., 1., 1.])\n",
            "La media por canal es: tensor([-2.2352e-08,  4.9671e-09,  1.9868e-08], grad_fn=<MeanBackward1>)\n",
            "La varianza por canal es: tensor([1., 1., 1.], grad_fn=<VarBackward1>)\n",
            "Las medias por canal de BN ahora son: tensor([ 7.9804,  2.7427, -1.3530])\n",
            "Las varianzas por canal de BN ahora son: tensor([487.3143, 547.6009, 640.8171])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNvplXz5xkUZ"
      },
      "source": [
        "### Revisitando AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGXdKoKfxkaa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSvQo9EFkFz2"
      },
      "source": [
        "## Manejo de Datos\n",
        "\n",
        "En un problema normal de Machine Learning, usualmente la gestión de datos no era muy importante dado que los datasets en general son pequeños. Sin embargo, dados los volúmenes de datos que requieren los modelos de aprendizaje profundo, se vuelve difícil mantener los datos en memoria. Por esto, se requiere consumirlos de manera parcelada para poder ocuparlos con las restricciones de hardware que tenemos.\n",
        "\n",
        "Pytorch resuelve el problema mediante dos abstracciones: las clases *Dataset* y *DataLoader*. \n",
        "\n",
        "* La clase *Dataset* trabaja como una interfaz sencilla para acceder nuestros datos físicos.\n",
        "* La clase *DataLoader* se encarga de agrupar los elementos de la clase *Dataset* en *batches* para pasarle a nuestro modelo.\n",
        "\n",
        "Usualmente, el mayor trabajo reside en definir una clase Dataset apropiada para nuestro conjunto de datos. Por suerte, si queremos trabajar con ciertos conjuntos de datos estándar, Pytorch ya tiene definido estos datasets por nosotros.\n",
        "\n",
        "Si no, lo único que tenemos que hacer es definir una clase que herede de torch.utils.data.Dataset y que implemente dos métodos:\n",
        "\n",
        "* \\_\\_len(self)\\_\\_: método que devuelva el tamaño total del dataset.\n",
        "* \\_\\_getitem\\_\\_(self, index): método que entregue un elemento particular del dataset dado un índice (index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQI4FW7tm5Kq"
      },
      "source": [
        "### Usar Datasets predefinidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUu0A4sIm56x",
        "outputId": "ab704d5a-3799-4df9-d655-f14a59a7f706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486,
          "referenced_widgets": [
            "f7b42ef04c0047f98e61e28d3bac7d24",
            "611c8dd6f5f84609b53b2de26bb14c2c",
            "563a4017edda47b9ad295d26c33cdba5",
            "fd8fa0127a5e4a5aa4b9ec901c62b6d2",
            "91185e0678894f919416ddb1af037d61",
            "b3180775a09e4bf09e9ccf4bf2588100",
            "41c5b240be864c60802aca248ea00614",
            "385f2a0078684bfaa158c64577fa2847",
            "98725b795e6a4313a213ed6d94df963d",
            "fb26f330e0384a68a4402a848af3778a",
            "4e65a1cfdbb54111b4b6a2c7b0536d7b",
            "0ffb3b339239455cad0761af02cc2543",
            "831f3b33dd1d4dae8c512d0c0b7714fa",
            "cd96c935ef7c4896a56de3f5c4d9f1b8",
            "c8cdbf6332ba470e8cc311a164372691",
            "5572bcca31c2431485a061648be497cc",
            "174ca99f02f243b5937fc15c6bd5aa69",
            "e26376e6475c417ab0040e5a04d90e7d",
            "20b5a356d7174842b6363876a57b7915",
            "7fb7694f9f29451e8d1421031c76963f",
            "b9e7fadf908c465aaf3edd81a1e5ceaf",
            "bd8273bb77fd4ec383d20a95125a692a",
            "75c3e3f1458f4fbf909024c2d7746f28",
            "82d9ed73bef94b878172d2838edac6bd",
            "a57d64a6cd8544d89a8434d998a6fa3b",
            "a1f172893ae64bf2b96e784565f50785",
            "4785dbb7936d474a85726c42d0a00db0",
            "82951eb7fd08459c8d27628df73e331a",
            "b0d6463239624d2ea0136142b5d8573c",
            "6521283e806249c496a5a366cecc5282",
            "e8a7a456d8164cf4b7a4e76fe5cee8d9",
            "6f7372ac218f41d986cc06e056b99dc2",
            "2a93a1220aa643d2bf0493cea706733f",
            "a0f2f1f22eb149f39c2b6711053ea489",
            "f4b9d812925348758736e8e23708e61b",
            "e724ad7d3639474fb60c5f248da57ada",
            "bfc9079cfd484d6c84451e9f79d67915",
            "6c4df75ab97747d7ac6e0ed64e110648",
            "e3daf2adaff44c3dac904b66c7381ef3",
            "78c4b6acd6d44f08a0725b867bbc599b"
          ]
        }
      },
      "source": [
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True)\n",
        "cifar = CIFAR10(root=\".\", train=True, download=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7b42ef04c0047f98e61e28d3bac7d24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98725b795e6a4313a213ed6d94df963d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "174ca99f02f243b5937fc15c6bd5aa69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a57d64a6cd8544d89a8434d998a6fa3b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a93a1220aa643d2bf0493cea706733f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Pu0YgnhTNZ"
      },
      "source": [
        "Veamos un ejemplo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcacrRSMhTUs",
        "outputId": "e5504e4b-2637-4cb2-fe0b-8d1ed9e00048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7FC93406F828>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U2JVToqhpas"
      },
      "source": [
        "Vemos que contiene dos elementos: el primero es una imagen en formato PIL y el segundo es la clase asociada a esa imagen (nuestro target o ground truth). La imagen se ve así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuDtFpjheKp",
        "outputId": "51242a79-7fa7-4df2-996a-7b5e23af0ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from IPython.display import display     # Esto no es Pytorch, es solo una librería\n",
        "                                        # para desplegar imágenes en Colab.\n",
        "display(mnist_train[0][0])\n",
        "display(cifar[0][0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FC930129710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJZElEQVR4nAXB2Y8dWX0A4LP8TtWp9W59l97stt1ux4zGHhiDRiYJGfECLyhv+e/CPxBFCEWRIuUBIQUemJFRBpuJ8d7r7bvVvVV1Tp0934d/+o8/q6p1TPwwCndG6XiY7fXziDKIE0Rhvam0DYN+jzijlOq6jifcISdk0+uXKDitNEWMUlrkeZZljHGpdMAEEdBK24Dh5auX1XI55AiP+J4rcDJp/bpxIeBIdFpIZZxfUswhWOspgTiORddar3E3IhQZpRLgjdJrZ9M0w4RhyhAhojPWGAoxJIBRjO6O+Mm0NxkPkzTDGEvVdUYFjKMkQTYEr3rD1JoQscQ5RKNY6c5YnEYxZAmPYotbErxFmGKUZ2nTCmMNwajebYFjWxRwdjgYJZT5rllr54kUlkSo7OcQxdW2BkDDIq13re5a2ZmAcJ5lRkvigMWxcwYoVspELCLeqmaDXIgpst5vWwWDGJI47mXJuGTOO4cQBYoIUd4AAATvlAyU3N5WzrhaCOF0npRIOYo8wYHGXLZdykoIoeu0NNajUDVdJUwjbGcIjPu8YJRzSmhIksRY5xEOQWsbnDY+mOB0gKjWrXNUOG+dr1tzuW4Z8WWDzc1SbsWdvdPJ5AgXW7VZNU27rbvlVn443zoKcDDOysjmaYSDQSjg4JUUBOFR0csyvtsue2VZd+bj5bJRNPLoMAVg8sOqUoEyHHpl8fwHz3bXLojQ22NKQNOQmLHjWTGZTOe7DoZFArqKGaRxqqQx3vb7gxCCdsSYLs3zq4V6+3G7qK2w6G5C//kfvjjaz//t23d/fHNjvQYS6mohGlUUDDnMOYs4TTGzzt45PijWNUyGI7nuCIZGGKktYCqMIwhJo/uDUrvw7uJqvXMBIkpJyd0Ear5WD8vZ9ZDMq1sl9IvXr4n1JitRb4oI9Hpp4UOnTdC7k3EGg73xIE8IYdVuY9qGOOeRDwzynBvE//rudatazmMeQZKlA2q/fTO3GlRvNh5wjEpjO6FlK4K2FhuNMGIEB0IZgFUquACIMMwYQijmLEUZIEIIMcjHSW95U4vl5v6Qqw7xLH304JCozlK2222AbosoGw0ePHh45/2nP33/+jICFUJjLRCIWMS89x5hjAnIzmAjEbJtu9OGWMIbUe9EfXgMwdZ39/CDAyY6fHj2NArdZmuS/git6PFsv2rb+3/3sByk5eDxZlFvtlsWZSTExjvvkTOWYBRCAIddcDaEkPAkL9KrhXx/sQAWovlVN188nLCf/9PDt5fr4nC8N5rdLub9fkY8iwi9XVwCrxbV9eV1w1jaL72UIQDBBHvvCMaYEBcQ9Pu5Bds0XTBuW28/fpo3TZNwcv1+N+XR4eHd/sE9VnvE2dHTn/Cby8QuHOratttPx9p5nOVH2UHRn9Wrm9v5ymDWaYVIyGKuZcMiBnW1Al0zTBBFQKlotoMi62dcbnaTg9Hhk5/95UK/fqOf7w+rSk8fPCVIaLXoB7+7XSXa7A+HlYvZk4Gsrv/nP397cb6gEUMIy4AMIsQYoBg52QSECbIO041Bu10ISu/3sh9//fXRo6/+/df/OstyquXlu7ez+z/go9Ms1GJ9m/iBlmJZi/743mh2IpuSlMhFHSbYGI2tw8FZC4ADcsZgQoCgIA32aDhKZ6n90bOzx8+/2tw2sd3ePzry2M8mY9tZUWltrZHgUP728uK7v3zz/Cs9mo129S1L0d5J5glx2lmlt4tK1Sl466TyUZYDMEr06WzAE3Jy9/jp33+9/+jJn//46zvHg9lnn0fjB5D2RNfIXT2/Ot/ML5wRScH39tj51Yvp/qEVTZAKtxsXZMAhiVk0Y7sYA6OwqYXrcJImlITJKD2/rh786BdHn/8CoYGp217RG5990cLw5Ys/KdnudtXy8hN1mnM4vHf45OzU0ozRPosMdJ34eOmtswQ1lKajbHowAiW7NAbMKSM2OJvk9Ff/8qvnv/x5uTedv/srJbaqt4sP/3dVu9/95jd5wjrVzKa9ssjeX5xrYocHJ2eff4lcvK4uRIc30uIAnfRNCKHpHvcR+KCRd9h6GwzGgcflF19+GTP26s8vNldvlerqzfr8zasmJMx1OdCSZ+NB73p+Y40RdXP+/hNCL5um5hBsPFnZMkl4WiQJxLXYWW8BIe+tBpY66zSy097gv377H8Ppy8n+sRZbxuI8K4HQjLHZZCTrTULj1WJptCt4opvmby++uf7+tbISMeoIzY4ylGkSd9zbAUoef3YPvMcRUA4eERxo5rVZLm+axU1idh7R4WDUPxhbpy6vbgIKhIC2lmKW8dR6RK1HODi9JR7vxEbHsjhQbVLVXnctGZX39yYjQnDM4yQgmyZ8MpoEo0ZF1Iut3s51vRSijsshyUaPnjzzkOhAPIamEd6hiAJnYK19fbH45tXVd2+v13bH+8CiqGlsK0NWjKRwJAKilfIh8jQWRlLqU55kxThKe9PJXr1ZCG3Gx6fCx5/9+KePv3hGgLeNEkJijDHy15dXn97fNEImeToeTnDH8HU2uN074/eO+kdvXt3AdEzMaiWdb1sUiAOAshxFjMl2lzBAGr75wx/uP5pfXNwQgtOYURonSdY2Ukpprc6T+PkPz3hRWmqdEfK8IzWfpMUPzz6b9KffXr+HO8dRD/M352K+CNrFeQ6t2DrfUETWi1Xd2M5sadgW+WB+s75oOx/wdDzC3myqTZzF/V4RUaK0Q8BaRXTDMk9Oj2cHs9H5xXy1EFAOmFyIwYSiLF3OVac1RKXWyBtnnNrKTZbEnehkt9TGOeNCoM1OlGVSlj0pxXK1yfMME4JtiCCJOYoienJ6IkX4/e9f/e/rWwAOvIyGOQGpWOJ3G0COJHzimHeqilJgEFGaquC10SFgHFDQnesQA4aiuNpspDa9fgmEEIgEsvNlvWls3W7/+3ffzwWCpmGI5nnWsSRkMe/1fLOTzW7eCGc6V0QjzphVCoBEBLGYYkzSHAgg62yUQNlP1+u6Dr4cjoTVf/uw+v678+mwnB6liPi9XgEXH5GqeDG2PDG9HA2H0LSiqsRmFW1WiHrqQ3DOIe8IQphgCiAdCRYxb6xYOykcsKoR2qH1Tn54s6pWrW7drDd7fPdwJxE4tmeiZ8orYpe8h/tjPiB2KHy1TqollS04G6FAvPWd7KIookDrzsumY0EXpPBkZwzEWeAs7kf6Pup//jR79OTpyenpT74SF1fN/wMWt9uTtWIfgAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FC930058BE0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJPBWG9Qh9CD"
      },
      "source": [
        "Sin embargo, una imagen en formato PIL no es un tensor de Pytorch. Tenemos que hacer algo para transformarla! Por suerte para nosotros, Pytorch nos ofrece transformaciones estándar para imágenes, en particular, una para transformar imágenes PIL a tensores. Veamos cómo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw_qKilQiTHk"
      },
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True, transform=ToTensor())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M-kU58jibL9",
        "outputId": "8556ab8e-9d70-44de-b6a8-88f82bf12b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train[9]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.7451,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5608, 0.9686, 0.6000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9686, 0.9490, 0.3373,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9882, 0.7333, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.7255, 0.0706, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.3490, 0.9255, 0.8510, 0.1843, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8471, 0.9922, 0.2353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.8314, 1.0000, 0.3176, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.9882, 0.2667, 0.0000,\n",
              "           0.0000, 0.0000, 0.1882, 0.9490, 0.9922, 0.3490, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5137, 0.9843, 0.8314, 0.0824, 0.0000,\n",
              "           0.0000, 0.0431, 0.6549, 0.9882, 0.7725, 0.0196, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1137, 0.9098, 0.9686, 0.2471, 0.0000, 0.0000,\n",
              "           0.0000, 0.6000, 0.9882, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1765, 0.8588, 0.9882, 0.5608, 0.0000, 0.0000, 0.0000,\n",
              "           0.4549, 0.9765, 0.9882, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
              "           0.3765, 0.9922, 1.0000, 0.9922, 0.7843, 0.4784, 0.0275, 0.0980,\n",
              "           0.7882, 0.9804, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608,\n",
              "           0.9882, 0.9882, 0.9922, 0.8510, 0.9882, 0.9882, 0.7843, 0.8902,\n",
              "           0.9882, 0.9059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9843,\n",
              "           0.9686, 0.9059, 0.2549, 0.1882, 0.7412, 0.9882, 0.9882, 0.9922,\n",
              "           0.9882, 0.9843, 0.8902, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8667,\n",
              "           0.3843, 0.0000, 0.0000, 0.0000, 0.1647, 0.7686, 0.9882, 0.9922,\n",
              "           0.9882, 0.9882, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.1137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.9373, 0.9882, 0.3373,\n",
              "           0.1647, 0.1647, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0588, 0.5804, 0.9922, 0.8549, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4745, 0.9882, 0.9059, 0.1098, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1216, 0.8667, 0.9843, 0.5059, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.8549, 0.9882, 0.6275, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4784, 0.9882, 0.3216, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]), 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TgMYxJCifaf"
      },
      "source": [
        "Ahora nuestro Dataset automáticamente transforma las imágenes PIL a tensores de Pytorch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRFZkdKJUOjP"
      },
      "source": [
        "### Crear un Dataset de ejemplo\n",
        "\n",
        "Vamos a crear un Dataset para el conjunto de datos Flowers que vimos el laboratorio pasado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSJdFURr_B8",
        "outputId": "a78a14e4-774e-4e6f-a2b6-9ae45c1d727b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/q53g4cmpnvzhnhi/flowers.tar.gz -q --show-progress\n",
        "!tar -xzf flowers.tar.gz"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flowers.tar.gz      100%[===================>] 328.99M  73.0MB/s    in 4.6s    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FXcvQ5VUOtH"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "class Flowers(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.imagenes = []       # Vincula el indice con un nombre de archivo\n",
        "        self.imgs_to_class = []  # Vincula el indice con una clase\n",
        "        self.imagenes, self.imgs_to_class = self.armar_indices(root)\n",
        "    \n",
        "    def armar_indices(self, root):\n",
        "        n_classes = len(listdir(root)) # El número de carpetas es la cantidad de clases\n",
        "        contador = 0\n",
        "        lista_imagenes = []\n",
        "        imgs_to_class = []\n",
        "        for clase in listdir(root):\n",
        "            directorio = join(root, clase)\n",
        "            for archivo in listdir(directorio):\n",
        "                lista_imagenes.append(archivo)\n",
        "                contador+=1\n",
        "                imgs_to_class.append(int(clase))\n",
        "\n",
        "        return lista_imagenes, imgs_to_class\n",
        "\n",
        "    def obtener_imagen(self, archivo):\n",
        "\n",
        "        im = Image.open(archivo)\n",
        "        return im\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        nombre_archivo = self.imagenes[idx]\n",
        "        clase = self.imgs_to_class[idx]\n",
        "        ruta_img = join(self.root, str(clase))\n",
        "        ruta_img = join(ruta_img, nombre_archivo)\n",
        "        img = self.obtener_imagen(ruta_img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, clase\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imagenes)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahbf-pLNsW-A",
        "outputId": "6a59ff91-95a7-41ab-a458-f32b8f376165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "transforms = Compose([Resize((224,224)), ToTensor()])\n",
        "f = Flowers('flowers_dataset/train', transform=transforms)\n",
        "display(f[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(tensor([[[0.0157, 0.0078, 0.0235,  ..., 0.1961, 0.2000, 0.1647],\n",
              "          [0.0000, 0.0000, 0.0157,  ..., 0.0588, 0.0431, 0.0471],\n",
              "          [0.0157, 0.0078, 0.0353,  ..., 0.1294, 0.1137, 0.1255],\n",
              "          ...,\n",
              "          [0.2078, 0.1804, 0.1569,  ..., 0.0627, 0.0784, 0.0902],\n",
              "          [0.2157, 0.1922, 0.1059,  ..., 0.0431, 0.0706, 0.0784],\n",
              "          [0.2078, 0.1882, 0.0627,  ..., 0.0353, 0.0431, 0.0275]],\n",
              " \n",
              "         [[0.1569, 0.1412, 0.1529,  ..., 0.4588, 0.4510, 0.4196],\n",
              "          [0.1098, 0.1059, 0.1490,  ..., 0.2706, 0.2510, 0.2667],\n",
              "          [0.1216, 0.1294, 0.1804,  ..., 0.3373, 0.3098, 0.3216],\n",
              "          ...,\n",
              "          [0.2000, 0.1765, 0.1529,  ..., 0.0392, 0.0392, 0.0471],\n",
              "          [0.1882, 0.1765, 0.1059,  ..., 0.0431, 0.0549, 0.0588],\n",
              "          [0.1529, 0.1608, 0.0627,  ..., 0.0471, 0.0471, 0.0314]],\n",
              " \n",
              "         [[0.1412, 0.1255, 0.1490,  ..., 0.5843, 0.5412, 0.4941],\n",
              "          [0.1176, 0.1176, 0.1686,  ..., 0.4118, 0.3176, 0.3059],\n",
              "          [0.1608, 0.1765, 0.2431,  ..., 0.4784, 0.4824, 0.5020],\n",
              "          ...,\n",
              "          [0.6824, 0.6235, 0.5412,  ..., 0.3843, 0.4431, 0.4627],\n",
              "          [0.6431, 0.5804, 0.4471,  ..., 0.3059, 0.3529, 0.3647],\n",
              "          [0.6000, 0.5294, 0.3608,  ..., 0.2588, 0.2784, 0.2588]]]), 26)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PE9qnWDnzjX"
      },
      "source": [
        "### Iterar sobre los datos\n",
        "\n",
        "Dado un Dataset, sea hecho por nosotros o uno predefinido, iterar sobre los datos es muy sencillo. Simplemente tenemos que crear un objeto DataLoader que toma como argumento el Dataset y definir el batch size con que queremos trabajar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9BrWXFcGKKF"
      },
      "source": [
        "Este código iterará por todos los batches de ejemplos de nuestro dataset y parará cuando se acaben. Es decir, esto corre por una **época**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5wPTQwiBx2W",
        "outputId": "8b1f9b0a-ab4e-4592-d4d1-284e1c9bd369",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dl = DataLoader(f, batch_size=32)\n",
        "\n",
        "for n_batch, (x, target) in enumerate(train_dl):\n",
        "    print(\"\\rN_Batch: {} input: {}- Label:{}\".format(n_batch, x.shape, target.shape), end=\"\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_Batch: 177 input: torch.Size([23, 3, 224, 224])- Label:torch.Size([23])"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShVxaAFkWY8"
      },
      "source": [
        "## Loop de Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pco2wPSLBlPB"
      },
      "source": [
        "### Optimización\n",
        "\n",
        "¿Como obtenemos los pesos óptimos para nuestra red? Si recordamos nuestras clases anteriores debemos optimizar la función de pérdida para tratar de encontrar los parámetros de nuestra red que minimizan su valor.\n",
        "\n",
        "Primero debemos definir la función de pérdida. Éstas están definidas en torch.nn también. Las usuales son:\n",
        "\n",
        "* CrossEntropyLoss: Entropía Cruzada, mide la distancia entre dos distribuciones de probabilidad. La función de pérdida más común para problemas de clasificación.\n",
        "* MSELoss: Error cuadrático medio. Pérdida usual en problemas de regresión.\n",
        "\n",
        "Hay más para revisar en la documentación de Pytorch (https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "Dado el resultado de nuestra red y el ground truth que deberíamos predecir, la pérdida es:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkR0nWLUDOrD"
      },
      "source": [
        "loss = funcion_perdida(output, target) # No correr este código, va a dar error! Es un ejemplo!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z61_pCzKDVPb"
      },
      "source": [
        "Súper, tenemos la pérdida, ¿cómo calculamos los gradientes?\n",
        "\n",
        "Para eso necesitamos un algoritmo de optimización. En el curso de Herramientas verán los algoritmos en detalle, pero les debería sonar Stochastic Gradient Descent (SGD), que es el algoritmo estándar de optimización. Este ya está implementado por el paquete torch.optim.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdfXdGgkEFXp"
      },
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "optimizer = SGD(model.parameters())     # Vinculamos el recién creado optimizador\n",
        "                                        # a los parámetros de nuestro modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRakjFJ1Ec8u"
      },
      "source": [
        "Esto por sí solo todavía no hace nada. El optimizador va a ir gestionando los gradientes que le llegan a cada parámetro de nuestro modelo. Actualizará los valores de los parámetros de acuerdo al algoritmo de optimización que implemente.\n",
        "\n",
        "Pero para gestionar gradientes tiene que sacarlos de alguna parte. ¡Esto lo hace backpropagation! Por suerte es muy fácil calcularlos en Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1SEJsy9FocF"
      },
      "source": [
        "loss.backward()                         # ¡Backpropagation! Eso es todo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHc9IlalF1sb"
      },
      "source": [
        "Luego uniendo todas las piezas, en cada iteración de nuestro algoritmo de entrenamiento haremos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3CqYbbljsJC"
      },
      "source": [
        "optimizer.zero_grad()                   # 1. Hacemos cero los gradientes de los parámetros\n",
        "output = model(input)                   # 2. Propagamos los datos de entrada por nuestro modelo\n",
        "loss = funcion_perdida(output, target)  # 3. Cálculamos la pérdida\n",
        "loss.backward()                         # 4. ¡Backpropagation! Calculamos los gradientes \n",
        "                                        # para nuestros parámetros. ¡Los gradientes \n",
        "                                        # dejan de ser 0!\n",
        "optimizer.step()                        # 5. Actualizamos los parámetros de nuestro modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2lKeEmPkFxN"
      },
      "source": [
        "## Evaluación de Rendimiento\n",
        "\n",
        "¿Cómo evaluamos el rendimiento? En problemas de clasificación lo que usualmente haremos es comparar el ground truth respecto a lo que predecimos. ¿Qué es lo que predecimos? Usualmente será la clase de mayor valor en su salida entre las N clases que tenemos que predecir. Esto lo podemos hacer usando la función *argmax* de Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDF-5Ei0_Kkh"
      },
      "source": [
        "output = model(input)                       # Tensor de salida de tamaño (batch_size, n_clases)\n",
        "preds = output.argmax(dim=1)                # Nos quedamos con el índice que tiene mayor valor\n",
        "                                            # entre las N clases.\n",
        "n_correctas = (preds == targets).sum()      # preds == targets entrega un tensor de 1s o 0s.\n",
        "total = targets.shape[0]                    # Total de ejemplos\n",
        "acc = n_correctas/total                     # Accuracy es correctas/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXwwivwjAKo"
      },
      "source": [
        "## Uniendo todo\n",
        "\n",
        "Vamos a unir todos estos componentes para armar un flujo de entrenamiento completo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZOhD3d40KXu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCdJwSCajFsr",
        "outputId": "34b3b089-2668-4d1b-df99-842d7f90c62f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 20\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.45 Correctas: 165.0 Total: 5687.0 Accuracy: 2.90%\n",
            "Epoca 2: Loss: 4.03 Correctas: 293.0 Total: 5687.0 Accuracy: 5.15%\n",
            "Epoca 3: Loss: 4.04 Correctas: 360.0 Total: 5687.0 Accuracy: 6.33%\n",
            "Epoca 4: Loss: 3.84 Correctas: 441.0 Total: 5687.0 Accuracy: 7.75%\n",
            "Epoca 5: Loss: 3.47 Correctas: 592.0 Total: 5687.0 Accuracy: 10.41%\n",
            "Epoca 6: Loss: 3.61 Correctas: 728.0 Total: 5687.0 Accuracy: 12.80%\n",
            "Epoca 7: Loss: 3.06 Correctas: 868.0 Total: 5687.0 Accuracy: 15.26%\n",
            "Epoca 8: Loss: 2.90 Correctas: 1086.0 Total: 5687.0 Accuracy: 19.10%\n",
            "Epoca 9: Loss: 2.91 Correctas: 1300.0 Total: 5687.0 Accuracy: 22.86%\n",
            "Epoca 10: Loss: 3.01 Correctas: 1357.0 Total: 5687.0 Accuracy: 23.86%\n",
            "Epoca 11: Loss: 2.78 Correctas: 1654.0 Total: 5687.0 Accuracy: 29.08%\n",
            "Epoca 12: Loss: 2.17 Correctas: 1933.0 Total: 5687.0 Accuracy: 33.99%\n",
            "Epoca 13: Loss: 2.43 Correctas: 2225.0 Total: 5687.0 Accuracy: 39.12%\n",
            "Epoca 14: Loss: 2.18 Correctas: 2500.0 Total: 5687.0 Accuracy: 43.96%\n",
            "Epoca 15: Loss: 1.54 Correctas: 2762.0 Total: 5687.0 Accuracy: 48.57%\n",
            "Epoca 16: Loss: 1.36 Correctas: 3105.0 Total: 5687.0 Accuracy: 54.60%\n",
            "Epoca 17: Loss: 1.06 Correctas: 3422.0 Total: 5687.0 Accuracy: 60.17%\n",
            "Epoca 18: Loss: 1.07 Correctas: 3764.0 Total: 5687.0 Accuracy: 66.19%\n",
            "Epoca 19: Loss: 0.76 Correctas: 4066.0 Total: 5687.0 Accuracy: 71.50%\n",
            "Epoca 20: Loss: 0.70 Correctas: 4409.0 Total: 5687.0 Accuracy: 77.53%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmpMxT9_ypG"
      },
      "source": [
        "### Evaluando el modelo en el conjunto de Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXaeSaTV-KzJ",
        "outputId": "85d4270f-68eb-48ab-e39d-13cc3129a115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 3.62 Correctas: 648.0 Total: 1738.0 Accuracy: 37.28%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Hrw55cmD-d"
      },
      "source": [
        "## Guardar el Modelo\n",
        "\n",
        "Una vez entrenado, querremos guardar el modelo para no tener que reentrenarlo cada vez que lo queramos usar. Esto es fácil de hacer en Pytorch. Hay dos formas de hacerlo:\n",
        "\n",
        "* La forma bruta es guardar el objeto completo usando torch.save. Esto guarda todo el objeto a disco. Por lo tanto ocupa más espacio. Pero este no es el mayor problema, sino que el modelo queda vinculado al computador en que se creó. Algo nada apetecible si queremos correr el modelo entrenado en otra máquina. Si se desea proseguir, se hace de la siguiente manera:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTj1Wvg_mYlI"
      },
      "source": [
        "torch.save(model, \"modelo_entrenado.pth\")\n",
        "\n",
        "modelo = torch.load(\"modelo_entrenado.pth\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjKpS6ndmd2d"
      },
      "source": [
        "* La forma más eficiente y correcta es simplemente guardar los pesos. Estos se encuentran en una estructura llamada *'state_dict'* en el modelo. Una vez guardados, para recuperar nuestro modelo, tenemos que crear un modelo nuevo y ocupar el método *'load_state_dict'* para cargar los pesos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2NceHcCmd_E",
        "outputId": "3a637f44-b959-4af3-aa35-d58b92cd216b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.save(model.state_dict(), \"pesos_modelo_entrenado.pth\") # Guardamos a disco los pesos\n",
        "\n",
        "modelo = MiAlexNet()                                # Modelo con pesos aleatorios\n",
        "pesos = torch.load(\"pesos_modelo_entrenado.pth\") # Cargamos los pesos a una variable\n",
        "modelo.load_state_dict(pesos)                       # ¡Los pesos se encuentran \n",
        "                                                    # cargados en el modelo!"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgIRqm5YaL6"
      },
      "source": [
        "## Actividades\n",
        "\n",
        "1. Entrene el modelo MiAlexNet por 10 épocas. ¿Qué resultados obtiene en train y test?\n",
        "2. Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. Entrénelo por 10 épocas. ¿Ve cambios en el rendimiento del modelo?\n",
        "3. Agregue capas de Batch Normalization (*BatchNorm2d*) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 épocas. ¿Ve algún cambio en el entrenamiento?\n",
        "4. Ocupe el modelo preentrenado en ImageNet de AlexNet. Entrénelo por 10 épocas. ¿Afecta en algo en rendimiento? Para ocupar el modelo preentrenado reemplace esta línea del código de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPXbZ7F6rpYH"
      },
      "source": [
        "model = MiAlexNet()     # Creamos el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJPwrpZOrpfL"
      },
      "source": [
        "Por esta otra línea:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjA6rheBq3YC"
      },
      "source": [
        "from torchvision.models import alexnet\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "model.features.requires_grad_(False)\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 102),\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Q3BQkaer6E"
      },
      "source": [
        "### Respuestas Actividad\n",
        "\n",
        "Por favor, sus respuestas a la actividad acá. No modificar el código anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APuyXZZteWZw"
      },
      "source": [
        "**Actividad 1**\n",
        "\n",
        "Entrene el modelo MiAlexNet por 10 épocas. ¿Qué resultados obtiene en train y test?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9OnSDXeeWhF",
        "outputId": "d78225ff-3113-49fa-c559-665742b38522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.51 Correctas: 147.0 Total: 5687.0 Accuracy: 2.58%\n",
            "Epoca 2: Loss: 4.38 Correctas: 218.0 Total: 5687.0 Accuracy: 3.83%\n",
            "Epoca 3: Loss: 3.98 Correctas: 342.0 Total: 5687.0 Accuracy: 6.01%\n",
            "Epoca 4: Loss: 3.81 Correctas: 455.0 Total: 5687.0 Accuracy: 8.00%\n",
            "Epoca 5: Loss: 3.33 Correctas: 606.0 Total: 5687.0 Accuracy: 10.66%\n",
            "Epoca 6: Loss: 3.51 Correctas: 756.0 Total: 5687.0 Accuracy: 13.29%\n",
            "Epoca 7: Loss: 3.16 Correctas: 895.0 Total: 5687.0 Accuracy: 15.74%\n",
            "Epoca 8: Loss: 3.00 Correctas: 992.0 Total: 5687.0 Accuracy: 17.44%\n",
            "Epoca 9: Loss: 2.87 Correctas: 1251.0 Total: 5687.0 Accuracy: 22.00%\n",
            "Epoca 10: Loss: 2.75 Correctas: 1378.0 Total: 5687.0 Accuracy: 24.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i19YL0VNq7qW",
        "outputId": "307d4f73-c9b2-4a86-c1c0-777b26d5a4ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.89 Correctas: 374.0 Total: 1738.0 Accuracy: 21.52%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUreTdqo3awe"
      },
      "source": [
        "Al reducir epochs de 20 a 10, el accuracy del test set baja de 37% a 22%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh3US3SM3aT0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVzxMB2JeWpn"
      },
      "source": [
        "**Actividad 2**\n",
        "\n",
        "Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. Entrénelo por 10 épocas. ¿Ve cambios en el rendimiento del modelo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srgh6pxteWvE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fcDropout = nn.Sequential( nn.Dropout() )\n",
        "        \n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fcDropout(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHOsgZFVp6CV",
        "outputId": "e3e56500-55b2-422b-9133-98aa804dd26b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.43 Correctas: 157.0 Total: 5687.0 Accuracy: 2.76%\n",
            "Epoca 2: Loss: 4.51 Correctas: 175.0 Total: 5687.0 Accuracy: 3.08%\n",
            "Epoca 3: Loss: 4.44 Correctas: 189.0 Total: 5687.0 Accuracy: 3.32%\n",
            "Epoca 4: Loss: 4.19 Correctas: 343.0 Total: 5687.0 Accuracy: 6.03%\n",
            "Epoca 5: Loss: 4.18 Correctas: 484.0 Total: 5687.0 Accuracy: 8.51%\n",
            "Epoca 6: Loss: 3.36 Correctas: 633.0 Total: 5687.0 Accuracy: 11.13%\n",
            "Epoca 7: Loss: 3.15 Correctas: 733.0 Total: 5687.0 Accuracy: 12.89%\n",
            "Epoca 8: Loss: 3.37 Correctas: 846.0 Total: 5687.0 Accuracy: 14.88%\n",
            "Epoca 9: Loss: 3.17 Correctas: 938.0 Total: 5687.0 Accuracy: 16.49%\n",
            "Epoca 10: Loss: 2.98 Correctas: 1095.0 Total: 5687.0 Accuracy: 19.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMmbpahrSZM",
        "outputId": "d08d82d2-7d35-4021-9c0c-662e8cc6e3a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 3.19 Correctas: 313.0 Total: 1738.0 Accuracy: 18.01%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPr29eGV3-kr"
      },
      "source": [
        "El accuracy del training y testing son muy similares (~18%), indicando que no hay problemas de overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDIv-92OeW7W"
      },
      "source": [
        "**Actividad 3**\n",
        "\n",
        "Agregue capas de Batch Normalization (BatchNorm2d) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 épocas. ¿Ve algún cambio en el entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz27SKTHeXCq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "\n",
        "        self.bn2 = nn.Sequential( BatchNorm2d(256, momentum = None, eps=0.0)  )                           \n",
        "\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "\n",
        "        self.bn3 = nn.Sequential( BatchNorm2d(384, momentum = None, eps=0.0)  )                           \n",
        "\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "\n",
        "        self.bn4 = nn.Sequential( BatchNorm2d(384, momentum = None, eps=0.0)  )                           \n",
        "\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096        \n",
        "        \n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdrsNw3PtC8g",
        "outputId": "e530c5e0-c727-4e9b-b720-a46a30151640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.52 Correctas: 159.0 Total: 5687.0 Accuracy: 2.80%\n",
            "Epoca 2: Loss: 4.55 Correctas: 166.0 Total: 5687.0 Accuracy: 2.92%\n",
            "Epoca 3: Loss: 4.41 Correctas: 168.0 Total: 5687.0 Accuracy: 2.95%\n",
            "Epoca 4: Loss: 4.61 Correctas: 173.0 Total: 5687.0 Accuracy: 3.04%\n",
            "Epoca 5: Loss: 4.55 Correctas: 169.0 Total: 5687.0 Accuracy: 2.97%\n",
            "Epoca 6: Loss: 4.52 Correctas: 172.0 Total: 5687.0 Accuracy: 3.02%\n",
            "Epoca 7: Loss: 4.43 Correctas: 180.0 Total: 5687.0 Accuracy: 3.17%\n",
            "Epoca 8: Loss: 4.56 Correctas: 172.0 Total: 5687.0 Accuracy: 3.02%\n",
            "Epoca 9: Loss: 4.58 Correctas: 180.0 Total: 5687.0 Accuracy: 3.17%\n",
            "Epoca 10: Loss: 4.55 Correctas: 166.0 Total: 5687.0 Accuracy: 2.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1OLBnybtFZK",
        "outputId": "72fa4eb9-238f-45fe-f120-a68a27d49933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 4.51 Correctas: 53.0 Total: 1738.0 Accuracy: 3.05%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL20N-G14HFh"
      },
      "source": [
        "El accuracy es muy bajo (3%), indicando que para el mismo numero de epochs, batch normalization da peores resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3esj4ZFEeX3w"
      },
      "source": [
        "**Actividad 4**\n",
        "\n",
        "Ocupe el modelo preentrenado en ImageNet de AlexNet. Entrénelo por 10 épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMb0lgVdeX9R",
        "outputId": "70eb3881-c6aa-450c-ee71-cc4d9c75fc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "29c7d49265ab46729d36817384d51ce2",
            "1bbed9c126cf4251b749313941252afd",
            "75e4e0a4470041d2ba76534e2f4892fc",
            "e0a5bbcf2a0f4afda22121429ef9a527",
            "2634b54a3c1b4f499ab08a36e68c6c03",
            "4f9dc304981c433b9c4434f30d5bf5b7",
            "411c298ba5724bdb894981f258a2b2c0",
            "1d2048bad8ff43b58b3e2974ba6ada36"
          ]
        }
      },
      "source": [
        "\n",
        "###TRAINING\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "model.features.requires_grad_(False)\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 102),\n",
        "        )\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos Dataset\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29c7d49265ab46729d36817384d51ce2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoca 1: Loss: 2.38 Correctas: 1139.0 Total: 5687.0 Accuracy: 20.03%\n",
            "Epoca 2: Loss: 1.61 Correctas: 2840.0 Total: 5687.0 Accuracy: 49.94%\n",
            "Epoca 3: Loss: 1.54 Correctas: 3503.0 Total: 5687.0 Accuracy: 61.60%\n",
            "Epoca 4: Loss: 1.02 Correctas: 3905.0 Total: 5687.0 Accuracy: 68.67%\n",
            "Epoca 5: Loss: 0.79 Correctas: 4103.0 Total: 5687.0 Accuracy: 72.15%\n",
            "Epoca 6: Loss: 0.75 Correctas: 4345.0 Total: 5687.0 Accuracy: 76.40%\n",
            "Epoca 7: Loss: 0.38 Correctas: 4441.0 Total: 5687.0 Accuracy: 78.09%\n",
            "Epoca 8: Loss: 0.53 Correctas: 4478.0 Total: 5687.0 Accuracy: 78.74%\n",
            "Epoca 9: Loss: 0.79 Correctas: 4658.0 Total: 5687.0 Accuracy: 81.91%\n",
            "Epoca 10: Loss: 0.98 Correctas: 4636.0 Total: 5687.0 Accuracy: 81.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvr0XBBZyn6_",
        "outputId": "7de14df8-cbb1-4cab-bfce-dc79412ef2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### EVAL\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.78 Correctas: 1354.0 Total: 1738.0 Accuracy: 77.91%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7va6b8y4Yv1"
      },
      "source": [
        "Al continuar entrenando el modelo original, aumenta el accuracy a un 82% en training, y 78% en testing. Esto indica que no hay problemas de overfitting, y en realidad era suficiente entrenar por más epochs en vez de aplicar dropout o overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_UFnyuJ4TmX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}